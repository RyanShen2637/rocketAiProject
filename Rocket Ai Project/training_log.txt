1/10/25

rocketTest1
 
Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording1.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Resuming from results\rocketTest1\Rocket Capabilities.
[INFO] Resuming training from step 250928.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 28.647 s. Mean Reward: -0.778. Std of Reward: 0.629. Training.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 74.886 s. Mean Reward: -0.846. Std of Reward: 0.533. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 121.945 s. Mean Reward: -0.912. Std of Reward: 0.410. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 169.739 s. Mean Reward: -0.833. Std of Reward: 0.553. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 214.942 s. Mean Reward: -0.806. Std of Reward: 0.591. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 255.674 s. Mean Reward: -0.783. Std of Reward: 0.622. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 297.120 s. Mean Reward: -0.803. Std of Reward: 0.596. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 340.955 s. Mean Reward: -0.606. Std of Reward: 0.795. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 379.683 s. Mean Reward: -0.800. Std of Reward: 0.600. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 399.261 s. Mean Reward: -0.725. Std of Reward: 0.689. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 417.969 s. Mean Reward: -0.660. Std of Reward: 0.752. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 435.845 s. Mean Reward: -0.308. Std of Reward: 0.951. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 455.504 s. Mean Reward: -0.450. Std of Reward: 0.893. Training.
[INFO] Exported results\rocketTest1\Rocket Capabilities\Rocket Capabilities-499969.onnx
[INFO] Exported results\rocketTest1\Rocket Capabilities\Rocket Capabilities-500033.onnx
[INFO] Copied results\rocketTest1\Rocket Capabilities\Rocket Capabilities-500033.onnx to results\rocketTest1\Rocket Capabilities.onnx.

----------------------------------------------------------------------------------------------------------------------

rocketTest2

 Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording1.demo
        init_path:      results\rocketTest1\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest1\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest2\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 57.018 s. Mean Reward: -0.791. Std of Reward: 0.612. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 74.481 s. Mean Reward: -0.778. Std of Reward: 0.629. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 92.117 s. Mean Reward: -0.798. Std of Reward: 0.603. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 120.330 s. Mean Reward: -0.811. Std of Reward: 0.586. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 170.490 s. Mean Reward: -0.917. Std of Reward: 0.400. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 188.099 s. Mean Reward: -0.783. Std of Reward: 0.623. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 205.444 s. Mean Reward: -0.710. Std of Reward: 0.705. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 226.988 s. Mean Reward: -0.719. Std of Reward: 0.695. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 244.491 s. Mean Reward: -0.611. Std of Reward: 0.792. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 261.881 s. Mean Reward: -0.489. Std of Reward: 0.872. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 279.689 s. Mean Reward: -0.753. Std of Reward: 0.658. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 302.969 s. Mean Reward: -0.714. Std of Reward: 0.700. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 336.854 s. Mean Reward: -0.783. Std of Reward: 0.622. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 383.137 s. Mean Reward: -0.483. Std of Reward: 0.876. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 410.943 s. Mean Reward: -0.500. Std of Reward: 0.866. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 454.589 s. Mean Reward: -0.737. Std of Reward: 0.676. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 475.341 s. Mean Reward: -0.676. Std of Reward: 0.736. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 492.524 s. Mean Reward: -0.636. Std of Reward: 0.771. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 509.912 s. Mean Reward: -0.581. Std of Reward: 0.814. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 527.746 s. Mean Reward: -0.750. Std of Reward: 0.661. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 544.975 s. Mean Reward: -0.526. Std of Reward: 0.850. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 562.815 s. Mean Reward: -0.435. Std of Reward: 0.901. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 580.351 s. Mean Reward: -0.111. Std of Reward: 0.994. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 597.538 s. Mean Reward: -0.238. Std of Reward: 0.971. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 614.879 s. Mean Reward: -0.304. Std of Reward: 0.953. Training.
[INFO] Exported results\rocketTest2\Rocket Capabilities\Rocket Capabilities-499989.onnx
[INFO] Exported results\rocketTest2\Rocket Capabilities\Rocket Capabilities-500053.onnx
[INFO] Copied results\rocketTest2\Rocket Capabilities\Rocket Capabilities-500053.onnx to results\rocketTest2\Rocket Capabilities.onnx.

-------------------------------------------------------------------------------------------------------------------------

1/17/25

rocketTest3

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording1.demo
        init_path:      results\rocketTest2\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest2\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest3\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 42.841 s. Mean Reward: -0.509. Std of Reward: 0.861. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 55.906 s. Mean Reward: -0.875. Std of Reward: 0.484. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 69.532 s. Mean Reward: -0.910. Std of Reward: 0.414. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 82.850 s. Mean Reward: -0.696. Std of Reward: 0.718. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 96.010 s. Mean Reward: -0.706. Std of Reward: 0.708. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 109.387 s. Mean Reward: -0.646. Std of Reward: 0.763. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 122.950 s. Mean Reward: -0.649. Std of Reward: 0.761. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 135.632 s. Mean Reward: -0.778. Std of Reward: 0.629. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 148.357 s. Mean Reward: -0.742. Std of Reward: 0.670. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 160.394 s. Mean Reward: -0.463. Std of Reward: 0.886. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 172.645 s. Mean Reward: -0.500. Std of Reward: 0.866. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 184.592 s. Mean Reward: -0.267. Std of Reward: 0.964. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 196.660 s. Mean Reward: -0.349. Std of Reward: 0.937. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 208.643 s. Mean Reward: -0.607. Std of Reward: 0.795. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 221.149 s. Mean Reward: -0.366. Std of Reward: 0.931. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 233.975 s. Mean Reward: -0.686. Std of Reward: 0.728. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 246.652 s. Mean Reward: -0.740. Std of Reward: 0.672. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 259.598 s. Mean Reward: -0.753. Std of Reward: 0.658. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 270.804 s. Mean Reward: -0.263. Std of Reward: 0.965. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 282.954 s. Mean Reward: -0.684. Std of Reward: 0.729. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 295.273 s. Mean Reward: -0.566. Std of Reward: 0.824. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 308.274 s. Mean Reward: -0.400. Std of Reward: 0.917. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 321.387 s. Mean Reward: -0.746. Std of Reward: 0.666. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 335.648 s. Mean Reward: -0.765. Std of Reward: 0.644. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 358.878 s. Mean Reward: -0.286. Std of Reward: 0.958. Training.
[INFO] Exported results\rocketTest3\Rocket Capabilities\Rocket Capabilities-499956.onnx
[INFO] Exported results\rocketTest3\Rocket Capabilities\Rocket Capabilities-500020.onnx
[INFO] Copied results\rocketTest3\Rocket Capabilities\Rocket Capabilities-500020.onnx to results\rocketTest3\Rocket Capabilities.onnx.

------------------------------------------------------------------------------------------------------------------------

rocketTest4

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording1.demo
        init_path:      results\rocketTest3\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest3\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest4\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 35.186 s. Mean Reward: -0.916. Std of Reward: 0.402. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 63.691 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 89.011 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 113.184 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 142.560 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 179.731 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 213.803 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 246.869 s. Mean Reward: -0.951. Std of Reward: 0.309. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 279.709 s. Mean Reward: -0.908. Std of Reward: 0.419. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 309.665 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 335.655 s. Mean Reward: -0.909. Std of Reward: 0.417. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 361.063 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 384.936 s. Mean Reward: -0.759. Std of Reward: 0.652. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 408.214 s. Mean Reward: -0.538. Std of Reward: 0.843. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 431.510 s. Mean Reward: -0.400. Std of Reward: 0.917. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 455.812 s. Mean Reward: 0.000. Std of Reward: 1.000. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 479.224 s. Mean Reward: -0.667. Std of Reward: 0.745. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 502.434 s. Mean Reward: -0.375. Std of Reward: 0.927. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 525.599 s. Mean Reward: -0.429. Std of Reward: 0.904. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 545.917 s. Mean Reward: -0.500. Std of Reward: 0.866. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 568.845 s. Mean Reward: -0.222. Std of Reward: 0.975. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 591.562 s. Mean Reward: -0.217. Std of Reward: 0.976. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 619.226 s. Mean Reward: -0.375. Std of Reward: 0.927. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 650.252 s. Mean Reward: -0.474. Std of Reward: 0.881. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 681.577 s. Mean Reward: -0.579. Std of Reward: 0.815. Training.
[INFO] Exported results\rocketTest4\Rocket Capabilities\Rocket Capabilities-499940.onnx
[INFO] Exported results\rocketTest4\Rocket Capabilities\Rocket Capabilities-500004.onnx
[INFO] Copied results\rocketTest4\Rocket Capabilities\Rocket Capabilities-500004.onnx to results\rocketTest4\Rocket Capabilities.onnx.

--------------------------------------------------------------------------------------------------------------------------

rocketTest5

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording1.demo
        init_path:      results\rocketTest4\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest4\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest5\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 35.991 s. Mean Reward: -0.277. Std of Reward: 0.961. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 59.391 s. Mean Reward: -0.754. Std of Reward: 0.656. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 83.151 s. Mean Reward: -0.838. Std of Reward: 0.546. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 106.487 s. Mean Reward: -0.714. Std of Reward: 0.700. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 129.917 s. Mean Reward: -0.535. Std of Reward: 0.845. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 153.707 s. Mean Reward: -0.548. Std of Reward: 0.836. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 177.779 s. Mean Reward: -0.125. Std of Reward: 0.992. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 201.782 s. Mean Reward: -0.462. Std of Reward: 0.887. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 226.264 s. Mean Reward: -0.789. Std of Reward: 0.614. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 255.764 s. Mean Reward: -0.467. Std of Reward: 0.884. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 285.586 s. Mean Reward: -0.649. Std of Reward: 0.761. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 314.823 s. Mean Reward: -0.900. Std of Reward: 0.436. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 343.986 s. Mean Reward: 0.111. Std of Reward: 0.994. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 374.915 s. Mean Reward: -0.286. Std of Reward: 0.958. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 400.093 s. Mean Reward: -0.133. Std of Reward: 0.991. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 429.652 s. Mean Reward: -0.368. Std of Reward: 0.930. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 468.587 s. Mean Reward: -0.400. Std of Reward: 0.917. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 494.476 s. Mean Reward: -0.478. Std of Reward: 0.878. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 515.502 s. Mean Reward: -0.438. Std of Reward: 0.899. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 539.864 s. Mean Reward: -0.467. Std of Reward: 0.884. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 562.786 s. Mean Reward: -0.067. Std of Reward: 0.998. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 585.803 s. Mean Reward: -0.412. Std of Reward: 0.911. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 609.316 s. Mean Reward: -0.818. Std of Reward: 0.575. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 632.537 s. Mean Reward: -0.385. Std of Reward: 0.923. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 655.437 s. Mean Reward: -0.111. Std of Reward: 0.994. Training.
[INFO] Exported results\rocketTest5\Rocket Capabilities\Rocket Capabilities-499956.onnx
[INFO] Exported results\rocketTest5\Rocket Capabilities\Rocket Capabilities-500020.onnx
[INFO] Copied results\rocketTest5\Rocket Capabilities\Rocket Capabilities-500020.onnx to results\rocketTest5\Rocket Capabilities.onnx.

----------------------------------------------------------------------------------------------------------------------
Moving forward from here, we added two more values to the observation space: targetVelocity and the rocket's velocity magnitude

rocketTest6

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[WARNING] Deleting TensorBoard data events.out.tfevents.1737175388.Halo_3.31576.0 that was left over from a previous run.
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 43.451 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 75.369 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 95.142 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 125.330 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 154.718 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 174.747 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 200.779 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 229.344 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 258.606 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 285.409 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 311.804 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 336.164 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 360.802 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 382.805 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 400.949 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 418.551 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 437.597 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 437.597 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 461.514 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 483.831 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 507.553 s. Mean Reward: -0.744. Std of Reward: 1.027. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 528.728 s. Mean Reward: -0.591. Std of Reward: 1.278. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 545.608 s. Mean Reward: -0.850. Std of Reward: 0.820. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 562.548 s. Mean Reward: -0.847. Std of Reward: 0.809. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 579.276 s. Mean Reward: -0.451. Std of Reward: 1.477. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 595.415 s. Mean Reward: -0.789. Std of Reward: 0.946. Training.
[INFO] Exported results\rocketTest6\Rocket Capabilities\Rocket Capabilities-499970.onnx
[INFO] Exported results\rocketTest6\Rocket Capabilities\Rocket Capabilities-500034.onnx
[INFO] Copied results\rocketTest6\Rocket Capabilities\Rocket Capabilities-500034.onnx to results\rocketTest6\Rocket Capabilities.onnx.

----------------------------------------------------------------------------------------------------------------------

rocketTest7

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      results\rocketTest6\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest6\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest7\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 39.431 s. Mean Reward: -0.267. Std of Reward: 1.721. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 83.128 s. Mean Reward: -0.668. Std of Reward: 1.194. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 127.264 s. Mean Reward: -0.832. Std of Reward: 1.148. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 165.765 s. Mean Reward: -0.582. Std of Reward: 1.413. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 207.851 s. Mean Reward: -0.167. Std of Reward: 1.840. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 244.558 s. Mean Reward: -0.202. Std of Reward: 1.925. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 271.296 s. Mean Reward: -0.443. Std of Reward: 1.653. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 299.491 s. Mean Reward: 0.140. Std of Reward: 2.136. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 326.055 s. Mean Reward: -0.277. Std of Reward: 1.711. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 353.694 s. Mean Reward: 0.210. Std of Reward: 2.175. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 380.912 s. Mean Reward: -0.132. Std of Reward: 1.965. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 407.727 s. Mean Reward: 0.635. Std of Reward: 2.263. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 433.229 s. Mean Reward: -0.187. Std of Reward: 2.034. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 459.266 s. Mean Reward: -0.749. Std of Reward: 1.321. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 486.223 s. Mean Reward: -0.872. Std of Reward: 0.865. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 513.684 s. Mean Reward: 1.069. Std of Reward: 2.365. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 541.383 s. Mean Reward: -0.605. Std of Reward: 1.247. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 566.984 s. Mean Reward: 0.343. Std of Reward: 2.277. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 592.831 s. Mean Reward: 0.585. Std of Reward: 1.977. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 632.447 s. Mean Reward: 0.691. Std of Reward: 2.417. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 660.281 s. Mean Reward: 0.556. Std of Reward: 2.018. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 686.693 s. Mean Reward: 0.160. Std of Reward: 2.019. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 713.813 s. Mean Reward: 0.047. Std of Reward: 1.954. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 738.443 s. Mean Reward: 0.759. Std of Reward: 2.263. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 767.280 s. Mean Reward: 0.806. Std of Reward: 2.179. Training.
[INFO] Exported results\rocketTest7\Rocket Capabilities\Rocket Capabilities-499985.onnx
[INFO] Exported results\rocketTest7\Rocket Capabilities\Rocket Capabilities-500049.onnx
[INFO] Copied results\rocketTest7\Rocket Capabilities\Rocket Capabilities-500049.onnx to results\rocketTest7\Rocket Capabilities.onnx.

--------------------------------------------------------------------------------------------------------------------------

1/24/25

rocketTest8

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      results\rocketTest7\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest7\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest8\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 43.321 s. Mean Reward: -0.373. Std of Reward: 1.485. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 67.756 s. Mean Reward: -0.689. Std of Reward: 1.287. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 91.659 s. Mean Reward: -0.586. Std of Reward: 1.678. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 116.159 s. Mean Reward: 0.740. Std of Reward: 2.382. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 140.231 s. Mean Reward: 0.115. Std of Reward: 2.277. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 164.583 s. Mean Reward: -1.500. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 188.341 s. Mean Reward: -0.242. Std of Reward: 1.795. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 212.718 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 237.197 s. Mean Reward: -0.269. Std of Reward: 1.821. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 262.512 s. Mean Reward: -1.500. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 286.129 s. Mean Reward: -1.500. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 313.386 s. Mean Reward: 0.065. Std of Reward: 2.049. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 327.847 s. Mean Reward: 0.113. Std of Reward: 2.087. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 341.809 s. Mean Reward: -1.420. Std of Reward: 0.183. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 356.122 s. Mean Reward: 0.082. Std of Reward: 1.339. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 370.553 s. Mean Reward: -0.315. Std of Reward: 1.472. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 384.851 s. Mean Reward: 0.066. Std of Reward: 1.404. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 399.518 s. Mean Reward: 0.300. Std of Reward: 1.857. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 412.246 s. Mean Reward: 0.310. Std of Reward: 1.824. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 426.235 s. Mean Reward: -0.350. Std of Reward: 1.509. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 440.120 s. Mean Reward: 0.447. Std of Reward: 1.943. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 453.808 s. Mean Reward: 0.348. Std of Reward: 1.809. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 468.148 s. Mean Reward: -0.092. Std of Reward: 1.487. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 482.019 s. Mean Reward: 0.157. Std of Reward: 1.884. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 495.776 s. Mean Reward: -0.336. Std of Reward: 1.621. Training.
[INFO] Exported results\rocketTest8\Rocket Capabilities\Rocket Capabilities-499990.onnx
[INFO] Exported results\rocketTest8\Rocket Capabilities\Rocket Capabilities-500054.onnx
[INFO] Copied results\rocketTest8\Rocket Capabilities\Rocket Capabilities-500054.onnx to results\rocketTest8\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

rocketTest9

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      results\rocketTest8\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest8\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest9\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 36.844 s. Mean Reward: -0.373. Std of Reward: 1.581. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 62.464 s. Mean Reward: -0.345. Std of Reward: 1.723. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 86.715 s. Mean Reward: 0.674. Std of Reward: 2.039. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 111.238 s. Mean Reward: 0.487. Std of Reward: 1.883. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 135.640 s. Mean Reward: 0.750. Std of Reward: 2.419. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 159.552 s. Mean Reward: -0.202. Std of Reward: 1.794. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 183.345 s. Mean Reward: 1.089. Std of Reward: 2.457. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 206.329 s. Mean Reward: -1.279. Std of Reward: 1.012. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 228.762 s. Mean Reward: 0.025. Std of Reward: 2.149. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 252.572 s. Mean Reward: -1.175. Std of Reward: 0.949. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 277.844 s. Mean Reward: -0.745. Std of Reward: 1.443. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 292.529 s. Mean Reward: -0.062. Std of Reward: 1.946. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 307.362 s. Mean Reward: -0.377. Std of Reward: 1.081. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 322.109 s. Mean Reward: 0.334. Std of Reward: 1.870. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 336.639 s. Mean Reward: 1.292. Std of Reward: 1.664. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 351.142 s. Mean Reward: 0.490. Std of Reward: 1.872. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 365.410 s. Mean Reward: 0.521. Std of Reward: 1.850. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 380.642 s. Mean Reward: 0.787. Std of Reward: 1.864. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 393.682 s. Mean Reward: -0.700. Std of Reward: 0.847. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 408.933 s. Mean Reward: 1.134. Std of Reward: 1.810. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 423.557 s. Mean Reward: 0.927. Std of Reward: 2.197. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 438.545 s. Mean Reward: 0.877. Std of Reward: 2.120. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 453.178 s. Mean Reward: -0.356. Std of Reward: 1.112. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 466.878 s. Mean Reward: 0.512. Std of Reward: 1.881. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 480.552 s. Mean Reward: 1.101. Std of Reward: 2.098. Training.
[INFO] Exported results\rocketTest9\Rocket Capabilities\Rocket Capabilities-499963.onnx
[INFO] Exported results\rocketTest9\Rocket Capabilities\Rocket Capabilities-500027.onnx
[INFO] Copied results\rocketTest9\Rocket Capabilities\Rocket Capabilities-500027.onnx to results\rocketTest9\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

rocketTest10

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      results\rocketTest9\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest9\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest10\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 33.945 s. Mean Reward: 0.153. Std of Reward: 1.851. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 57.497 s. Mean Reward: 0.622. Std of Reward: 2.022. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 80.472 s. Mean Reward: 1.319. Std of Reward: 2.314. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 103.347 s. Mean Reward: -0.467. Std of Reward: 1.572. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 126.228 s. Mean Reward: -0.290. Std of Reward: 1.881. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 149.246 s. Mean Reward: 1.139. Std of Reward: 1.583. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 172.390 s. Mean Reward: -0.095. Std of Reward: 1.635. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 195.613 s. Mean Reward: -0.022. Std of Reward: 1.572. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 218.527 s. Mean Reward: -0.621. Std of Reward: 1.499. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 242.295 s. Mean Reward: -0.205. Std of Reward: 1.755. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 265.800 s. Mean Reward: 1.139. Std of Reward: 1.985. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 289.090 s. Mean Reward: 0.720. Std of Reward: 1.915. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 312.778 s. Mean Reward: 0.661. Std of Reward: 2.061. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 335.534 s. Mean Reward: 0.380. Std of Reward: 1.910. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 358.851 s. Mean Reward: 0.151. Std of Reward: 1.644. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 382.074 s. Mean Reward: 0.709. Std of Reward: 1.991. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 405.367 s. Mean Reward: -0.031. Std of Reward: 1.455. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 429.051 s. Mean Reward: -0.293. Std of Reward: 1.416. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 449.032 s. Mean Reward: 0.354. Std of Reward: 1.895. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 472.801 s. Mean Reward: 0.471. Std of Reward: 1.676. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 497.070 s. Mean Reward: 0.305. Std of Reward: 1.997. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 520.169 s. Mean Reward: 0.729. Std of Reward: 1.742. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 543.881 s. Mean Reward: 0.270. Std of Reward: 1.815. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 566.563 s. Mean Reward: 0.291. Std of Reward: 1.861. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 589.142 s. Mean Reward: 0.828. Std of Reward: 2.052. Training.
[INFO] Exported results\rocketTest10\Rocket Capabilities\Rocket Capabilities-499985.onnx
[INFO] Exported results\rocketTest10\Rocket Capabilities\Rocket Capabilities-500049.onnx
[INFO] Copied results\rocketTest10\Rocket Capabilities\Rocket Capabilities-500049.onnx to results\rocketTest10\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

rocketTest11

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      results\rocketTest10\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest10\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest11\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 39.893 s. Mean Reward: 1.188. Std of Reward: 2.163. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 80.810 s. Mean Reward: -0.085. Std of Reward: 1.688. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 103.557 s. Mean Reward: 0.186. Std of Reward: 1.935. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 126.203 s. Mean Reward: -0.532. Std of Reward: 1.599. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 148.803 s. Mean Reward: -0.159. Std of Reward: 1.431. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 172.114 s. Mean Reward: 1.091. Std of Reward: 2.053. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 195.220 s. Mean Reward: 0.651. Std of Reward: 2.092. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 218.616 s. Mean Reward: 0.261. Std of Reward: 1.778. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 241.669 s. Mean Reward: 0.645. Std of Reward: 1.909. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 265.046 s. Mean Reward: 0.727. Std of Reward: 1.997. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 288.389 s. Mean Reward: 1.048. Std of Reward: 1.903. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 311.120 s. Mean Reward: 0.054. Std of Reward: 1.511. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 333.831 s. Mean Reward: 0.243. Std of Reward: 1.750. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 356.609 s. Mean Reward: 0.506. Std of Reward: 2.018. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 379.473 s. Mean Reward: 0.247. Std of Reward: 1.850. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 402.620 s. Mean Reward: 0.181. Std of Reward: 1.634. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 425.544 s. Mean Reward: 0.409. Std of Reward: 1.829. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 448.750 s. Mean Reward: 0.989. Std of Reward: 2.176. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 468.925 s. Mean Reward: 0.476. Std of Reward: 1.767. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 499.706 s. Mean Reward: 0.411. Std of Reward: 2.044. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 522.657 s. Mean Reward: 0.797. Std of Reward: 2.145. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 545.039 s. Mean Reward: 0.719. Std of Reward: 2.167. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 568.142 s. Mean Reward: 0.715. Std of Reward: 2.150. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 591.006 s. Mean Reward: 1.392. Std of Reward: 1.903. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 614.467 s. Mean Reward: 0.696. Std of Reward: 2.120. Training.
[INFO] Exported results\rocketTest11\Rocket Capabilities\Rocket Capabilities-499998.onnx
[INFO] Exported results\rocketTest11\Rocket Capabilities\Rocket Capabilities-500062.onnx
[INFO] Copied results\rocketTest11\Rocket Capabilities\Rocket Capabilities-500062.onnx to results\rocketTest11\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

rocketTest12

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      results\rocketTest11\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest11\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest12\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 30.152 s. Mean Reward: 0.904. Std of Reward: 2.236. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 52.893 s. Mean Reward: 0.108. Std of Reward: 1.913. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 75.004 s. Mean Reward: 0.812. Std of Reward: 2.109. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 97.670 s. Mean Reward: 0.715. Std of Reward: 1.939. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 121.156 s. Mean Reward: 1.283. Std of Reward: 2.180. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 144.190 s. Mean Reward: 0.151. Std of Reward: 1.744. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 167.260 s. Mean Reward: 1.201. Std of Reward: 1.836. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 195.694 s. Mean Reward: 1.613. Std of Reward: 2.125. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 218.279 s. Mean Reward: -0.169. Std of Reward: 1.144. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 241.259 s. Mean Reward: 1.084. Std of Reward: 2.163. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 264.259 s. Mean Reward: 1.403. Std of Reward: 1.888. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 287.454 s. Mean Reward: 0.613. Std of Reward: 1.597. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 310.316 s. Mean Reward: 0.593. Std of Reward: 1.627. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 333.096 s. Mean Reward: 1.145. Std of Reward: 1.216. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 356.374 s. Mean Reward: 0.909. Std of Reward: 1.989. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 379.423 s. Mean Reward: 1.397. Std of Reward: 1.909. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 402.606 s. Mean Reward: 0.938. Std of Reward: 1.910. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 425.662 s. Mean Reward: 1.357. Std of Reward: 1.981. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 445.085 s. Mean Reward: 0.806. Std of Reward: 1.620. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 467.634 s. Mean Reward: 0.971. Std of Reward: 1.824. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 490.100 s. Mean Reward: 1.800. Std of Reward: 1.368. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 512.941 s. Mean Reward: 1.188. Std of Reward: 2.125. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 535.434 s. Mean Reward: 1.516. Std of Reward: 2.110. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 557.951 s. Mean Reward: 1.343. Std of Reward: 2.283. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 581.305 s. Mean Reward: 1.553. Std of Reward: 2.121. Training.
[INFO] Exported results\rocketTest12\Rocket Capabilities\Rocket Capabilities-499981.onnx
[INFO] Exported results\rocketTest12\Rocket Capabilities\Rocket Capabilities-500045.onnx
[INFO] Copied results\rocketTest12\Rocket Capabilities\Rocket Capabilities-500045.onnx to results\rocketTest12\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

rocketTest13

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording3.demo
        init_path:      results\rocketTest12\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording3.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest12\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest13\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 29.536 s. Mean Reward: 2.219. Std of Reward: 2.242. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 52.789 s. Mean Reward: 1.024. Std of Reward: 2.173. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 75.314 s. Mean Reward: 1.871. Std of Reward: 1.998. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 98.280 s. Mean Reward: 1.172. Std of Reward: 1.703. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 121.706 s. Mean Reward: 0.654. Std of Reward: 1.730. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 144.885 s. Mean Reward: 0.649. Std of Reward: 1.369. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 167.952 s. Mean Reward: 0.169. Std of Reward: 1.632. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 191.298 s. Mean Reward: 2.018. Std of Reward: 2.230. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 213.846 s. Mean Reward: 0.548. Std of Reward: 1.527. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 236.580 s. Mean Reward: 0.936. Std of Reward: 1.880. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 259.659 s. Mean Reward: 1.165. Std of Reward: 1.944. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 282.264 s. Mean Reward: 1.040. Std of Reward: 1.863. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 305.030 s. Mean Reward: 1.222. Std of Reward: 2.234. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 327.744 s. Mean Reward: 0.884. Std of Reward: 1.999. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 350.892 s. Mean Reward: 1.683. Std of Reward: 1.638. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 373.802 s. Mean Reward: 0.815. Std of Reward: 2.184. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 396.797 s. Mean Reward: 1.022. Std of Reward: 2.344. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 419.749 s. Mean Reward: 0.343. Std of Reward: 1.739. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 439.088 s. Mean Reward: 1.138. Std of Reward: 1.871. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 462.012 s. Mean Reward: -0.390. Std of Reward: 1.264. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 484.209 s. Mean Reward: -0.140. Std of Reward: 1.636. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 506.824 s. Mean Reward: -0.417. Std of Reward: 1.437. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 529.698 s. Mean Reward: -0.191. Std of Reward: 1.675. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 552.245 s. Mean Reward: 0.730. Std of Reward: 2.144. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 575.616 s. Mean Reward: 0.101. Std of Reward: 1.816. Training.
[INFO] Exported results\rocketTest13\Rocket Capabilities\Rocket Capabilities-499962.onnx
[INFO] Exported results\rocketTest13\Rocket Capabilities\Rocket Capabilities-500026.onnx
[INFO] Copied results\rocketTest13\Rocket Capabilities\Rocket Capabilities-500026.onnx to results\rocketTest13\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

NEW CHANGE: Added cumulative punishments for the rocket going up

rocketTest14

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording4.demo
        init_path:      results\rocketTest13\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording4.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest13\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest14\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 41.748 s. Mean Reward: -0.182. Std of Reward: 2.679. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 69.957 s. Mean Reward: -6.212. Std of Reward: 3.160. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 103.090 s. Mean Reward: -9.163. Std of Reward: 3.663. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 134.964 s. Mean Reward: -6.885. Std of Reward: 6.090. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 167.416 s. Mean Reward: -3.492. Std of Reward: 5.383. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 198.393 s. Mean Reward: -5.268. Std of Reward: 4.975. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 230.951 s. Mean Reward: -4.262. Std of Reward: 1.876. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 263.739 s. Mean Reward: -2.872. Std of Reward: 4.516. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 298.152 s. Mean Reward: -2.591. Std of Reward: 3.810. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 332.989 s. Mean Reward: -0.700. Std of Reward: 3.539. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 365.190 s. Mean Reward: -0.810. Std of Reward: 4.047. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 399.388 s. Mean Reward: -0.595. Std of Reward: 3.521. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 423.389 s. Mean Reward: 0.804. Std of Reward: 2.799. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 440.763 s. Mean Reward: 0.481. Std of Reward: 2.775. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 457.148 s. Mean Reward: 0.357. Std of Reward: 2.763. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 474.883 s. Mean Reward: 0.253. Std of Reward: 2.695. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 492.000 s. Mean Reward: 0.869. Std of Reward: 2.594. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 507.938 s. Mean Reward: 0.370. Std of Reward: 2.654. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 526.452 s. Mean Reward: 0.235. Std of Reward: 2.618. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 542.792 s. Mean Reward: 0.701. Std of Reward: 2.838. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 558.454 s. Mean Reward: 0.105. Std of Reward: 2.977. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 590.406 s. Mean Reward: -0.187. Std of Reward: 2.922. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 611.651 s. Mean Reward: 1.319. Std of Reward: 2.433. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 627.785 s. Mean Reward: 0.361. Std of Reward: 2.794. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 644.781 s. Mean Reward: 0.771. Std of Reward: 2.859. Training.
[INFO] Exported results\rocketTest14\Rocket Capabilities\Rocket Capabilities-499997.onnx
[INFO] Exported results\rocketTest14\Rocket Capabilities\Rocket Capabilities-500061.onnx
[INFO] Copied results\rocketTest14\Rocket Capabilities\Rocket Capabilities-500061.onnx to results\rocketTest14\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest15 VERSION 1 MODEL

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording4.demo
        init_path:      results\rocketTest14\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording4.demo
          steps:        0
          steps:        0
          strength:     0.5
          strength:     0.5
          samples_per_update:   0
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
          num_epoch:    None
          batch_size:   None
          batch_size:   None
[INFO] Initializing from results\rocketTest14\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest15\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` onC:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 35.398 s. Mean Reward: 1.191. Std of Reward: 2.449. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 63.243 s. Mean Reward: -1.255. Std of Reward: 2.597. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 89.134 s. Mean Reward: -3.431. Std of Reward: 2.609. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 108.231 s. Mean Reward: -0.928. Std of Reward: 0.685. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 127.384 s. Mean Reward: -8.301. Std of Reward: 3.789. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 146.572 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 178.975 s. Mean Reward: -0.602. Std of Reward: 2.227. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 196.938 s. Mean Reward: -2.588. Std of Reward: 3.642. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 215.240 s. Mean Reward: 0.437. Std of Reward: 2.348. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 232.905 s. Mean Reward: -1.906. Std of Reward: 3.705. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 251.237 s. Mean Reward: 0.877. Std of Reward: 3.483. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 273.721 s. Mean Reward: 0.307. Std of Reward: 3.169. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 297.568 s. Mean Reward: -0.395. Std of Reward: 3.085. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 315.715 s. Mean Reward: 1.243. Std of Reward: 2.946. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 338.623 s. Mean Reward: 1.547. Std of Reward: 2.307. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 352.104 s. Mean Reward: -0.257. Std of Reward: 2.434. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 369.638 s. Mean Reward: 0.658. Std of Reward: 3.308. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 384.561 s. Mean Reward: 1.473. Std of Reward: 2.569. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 402.390 s. Mean Reward: 1.090. Std of Reward: 2.721. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 419.953 s. Mean Reward: 0.573. Std of Reward: 2.910. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 437.612 s. Mean Reward: 0.947. Std of Reward: 2.651. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 455.657 s. Mean Reward: 1.608. Std of Reward: 2.785. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 474.322 s. Mean Reward: 1.041. Std of Reward: 2.513. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 492.847 s. Mean Reward: 1.804. Std of Reward: 2.450. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 511.615 s. Mean Reward: 2.104. Std of Reward: 2.289. Training.
[INFO] Exported results\rocketTest15\Rocket Capabilities\Rocket Capabilities-499974.onnx
[INFO] Exported results\rocketTest15\Rocket Capabilities\Rocket Capabilities-500038.onnx
[INFO] Copied results\rocketTest15\Rocket Capabilities\Rocket Capabilities-500038.onnx to results\rocketTest15\Rocket Capabilities.onnx.

________________________________________________________________________________________________________________________

rocketTest16: Added variable height and fixed the last height to actually adjust + doubled environments from 18 to 36

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording4.demo
        init_path:      results\rocketTest15\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording4.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest15\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest16\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 20.590 s. Mean Reward: 0.673. Std of Reward: 2.481. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 31.743 s. Mean Reward: -1.014. Std of Reward: 3.889. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 43.082 s. Mean Reward: -2.599. Std of Reward: 5.665. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 53.336 s. Mean Reward: -4.102. Std of Reward: 7.882. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 64.448 s. Mean Reward: -3.807. Std of Reward: 8.019. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 76.120 s. Mean Reward: -2.342. Std of Reward: 6.592. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 88.112 s. Mean Reward: -5.969. Std of Reward: 10.237. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 99.923 s. Mean Reward: -6.391. Std of Reward: 12.190. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 112.059 s. Mean Reward: -2.776. Std of Reward: 7.142. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 122.776 s. Mean Reward: -4.277. Std of Reward: 10.461. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 137.954 s. Mean Reward: -2.490. Std of Reward: 7.451. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 149.516 s. Mean Reward: -6.769. Std of Reward: 13.223. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 161.227 s. Mean Reward: -4.834. Std of Reward: 9.513. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 172.407 s. Mean Reward: -5.608. Std of Reward: 9.503. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 183.970 s. Mean Reward: -2.363. Std of Reward: 5.540. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 196.088 s. Mean Reward: -5.641. Std of Reward: 9.838. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 196.088 s. Mean Reward: -5.641. Std of Reward: 9.838. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 205.773 s. Mean Reward: -5.946. Std of Reward: 10.655. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 216.902 s. Mean Reward: -2.999. Std of Reward: 11.034. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 227.682 s. Mean Reward: -3.835. Std of Reward: 7.746. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 239.623 s. Mean Reward: -5.413. Std of Reward: 12.669. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 250.387 s. Mean Reward: -2.620. Std of Reward: 6.781. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 260.749 s. Mean Reward: -3.511. Std of Reward: 10.935. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 272.473 s. Mean Reward: -6.547. Std of Reward: 12.953. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 283.240 s. Mean Reward: -1.136. Std of Reward: 4.917. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 293.759 s. Mean Reward: -3.615. Std of Reward: 11.725. Training.
[INFO] Exported results\rocketTest16\Rocket Capabilities\Rocket Capabilities-499968.onnx
[INFO] Exported results\rocketTest16\Rocket Capabilities\Rocket Capabilities-500032.onnx
[INFO] Copied results\rocketTest16\Rocket Capabilities\Rocket Capabilities-500032.onnx to results\rocketTest16\Rocket Capabilities.onnx.

________________________________________________________________________________________________________________________

rocketTest17

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording4.demo
        init_path:      results\rocketTest16\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording4.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest16\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest17\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 29.467 s. Mean Reward: 0.237. Std of Reward: 2.333. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 47.351 s. Mean Reward: -1.620. Std of Reward: 5.116. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 65.121 s. Mean Reward: -1.040. Std of Reward: 4.735. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 83.596 s. Mean Reward: -2.737. Std of Reward: 6.582. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 101.094 s. Mean Reward: -4.262. Std of Reward: 8.188. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 118.651 s. Mean Reward: -4.866. Std of Reward: 8.212. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 135.868 s. Mean Reward: -4.259. Std of Reward: 7.784. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 153.240 s. Mean Reward: -4.732. Std of Reward: 11.566. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 170.763 s. Mean Reward: -5.901. Std of Reward: 10.693. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 188.181 s. Mean Reward: -5.380. Std of Reward: 9.748. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 206.710 s. Mean Reward: -3.335. Std of Reward: 9.125. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 224.346 s. Mean Reward: -3.522. Std of Reward: 9.092. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 242.319 s. Mean Reward: -4.504. Std of Reward: 11.482. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 260.912 s. Mean Reward: -3.438. Std of Reward: 4.680. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 260.912 s. Mean Reward: -3.438. Std of Reward: 4.680. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 278.089 s. Mean Reward: -4.171. Std of Reward: 14.358. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 278.089 s. Mean Reward: -4.171. Std of Reward: 14.358. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 295.710 s. Mean Reward: -4.192. Std of Reward: 10.330. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 295.710 s. Mean Reward: -4.192. Std of Reward: 10.330. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 314.262 s. Mean Reward: -7.090. Std of Reward: 13.946. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 328.968 s. Mean Reward: -3.551. Std of Reward: 9.368. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 346.811 s. Mean Reward: -3.447. Std of Reward: 7.656. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 364.484 s. Mean Reward: -4.937. Std of Reward: 10.099. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 364.484 s. Mean Reward: -4.937. Std of Reward: 10.099. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 381.847 s. Mean Reward: -1.776. Std of Reward: 6.208. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 399.220 s. Mean Reward: -0.950. Std of Reward: 4.331. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 416.529 s. Mean Reward: -4.127. Std of Reward: 13.840. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 434.310 s. Mean Reward: -2.043. Std of Reward: 6.355. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 452.173 s. Mean Reward: -2.844. Std of Reward: 10.138. Training.
[INFO] Exported results\rocketTest17\Rocket Capabilities\Rocket Capabilities-499984.onnx
[INFO] Exported results\rocketTest17\Rocket Capabilities\Rocket Capabilities-500048.onnx
[INFO] Copied results\rocketTest17\Rocket Capabilities\Rocket Capabilities-500048.onnx to results\rocketTest17\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest18: upped the base reward of success from 1 to 10 to better reflect green > red

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording4.demo
        init_path:      results\rocketTest17\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        threaded:       False
        self_play:      None
        self_play:      None
        behavioral_cloning:
        behavioral_cloning:
          demo_path:    rocketRecordings/recording4.demo
          steps:        0
          steps:        0
          strength:     0.5
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          samples_per_update:   0
          num_epoch:    None
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest17\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest18\Rocket Capabilities.
[INFO] Starting training from step 0 and saving to results\rocketTest18\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` onC:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches  tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorSof matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
hape.cpp:3641.)
  return func(*args, **kwargs)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 24.652 s. Mean Reward: 6.186. Std of Reward: 6.850. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 41.403 s. Mean Reward: 4.870. Std of Reward: 6.510. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 41.403 s. Mean Reward: 4.870. Std of Reward: 6.510. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 57.614 s. Mean Reward: 4.196. Std of Reward: 6.301. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 74.250 s. Mean Reward: 1.686. Std of Reward: 7.864. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 90.416 s. Mean Reward: -1.686. Std of Reward: 8.876. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 106.855 s. Mean Reward: -2.004. Std of Reward: 12.566. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 123.455 s. Mean Reward: 2.764. Std of Reward: 14.355. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 143.408 s. Mean Reward: -4.282. Std of Reward: 10.413. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 159.554 s. Mean Reward: -0.830. Std of Reward: 10.158. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 168.415 s. Mean Reward: -0.741. Std of Reward: 12.866. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 177.662 s. Mean Reward: 0.909. Std of Reward: 11.279. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 186.756 s. Mean Reward: -0.677. Std of Reward: 9.518. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 196.283 s. Mean Reward: -1.078. Std of Reward: 13.166. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 205.126 s. Mean Reward: 1.600. Std of Reward: 8.898. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 214.573 s. Mean Reward: 3.525. Std of Reward: 10.581. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 224.380 s. Mean Reward: 3.486. Std of Reward: 9.014. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 233.744 s. Mean Reward: 2.209. Std of Reward: 12.337. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 241.715 s. Mean Reward: 1.971. Std of Reward: 13.091. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 258.172 s. Mean Reward: 3.062. Std of Reward: 7.813. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 268.311 s. Mean Reward: 2.747. Std of Reward: 11.365. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 277.571 s. Mean Reward: 3.351. Std of Reward: 8.832. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 286.718 s. Mean Reward: 2.438. Std of Reward: 8.320. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 296.139 s. Mean Reward: 0.581. Std of Reward: 11.870. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 305.395 s. Mean Reward: 3.141. Std of Reward: 8.509. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 314.585 s. Mean Reward: 1.425. Std of Reward: 9.901. Training.
[INFO] Exported results\rocketTest18\Rocket Capabilities\Rocket Capabilities-499969.onnx
[INFO] Exported results\rocketTest18\Rocket Capabilities\Rocket Capabilities-500033.onnx
[INFO] Copied results\rocketTest18\Rocket Capabilities\Rocket Capabilities-500033.onnx to results\rocketTest18\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

rocketTest19

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording4.demo
        init_path:      results\rocketTest18\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording4.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest18\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest19\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 32.175 s. Mean Reward: 6.451. Std of Reward: 6.802. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 47.990 s. Mean Reward: 2.436. Std of Reward: 6.521. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 63.567 s. Mean Reward: 3.960. Std of Reward: 7.789. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 79.853 s. Mean Reward: 1.785. Std of Reward: 7.687. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 95.303 s. Mean Reward: 4.842. Std of Reward: 8.241. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 111.417 s. Mean Reward: 3.283. Std of Reward: 10.735. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 127.827 s. Mean Reward: 2.080. Std of Reward: 10.564. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 144.163 s. Mean Reward: 1.263. Std of Reward: 10.300. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 160.319 s. Mean Reward: 3.133. Std of Reward: 8.716. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 176.936 s. Mean Reward: 1.605. Std of Reward: 11.703. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 195.791 s. Mean Reward: 1.705. Std of Reward: 11.192. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 212.437 s. Mean Reward: 4.385. Std of Reward: 9.987. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 228.744 s. Mean Reward: 2.479. Std of Reward: 10.685. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 245.391 s. Mean Reward: 2.016. Std of Reward: 8.371. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 262.321 s. Mean Reward: 1.256. Std of Reward: 11.719. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 278.896 s. Mean Reward: 3.486. Std of Reward: 8.161. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 295.079 s. Mean Reward: 1.916. Std of Reward: 12.517. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 308.026 s. Mean Reward: 2.761. Std of Reward: 9.767. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 324.820 s. Mean Reward: 4.364. Std of Reward: 7.488. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 340.921 s. Mean Reward: 5.751. Std of Reward: 8.733. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 356.910 s. Mean Reward: 2.972. Std of Reward: 9.810. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 377.131 s. Mean Reward: 3.256. Std of Reward: 8.888. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 394.210 s. Mean Reward: 4.930. Std of Reward: 10.894. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 411.731 s. Mean Reward: 4.456. Std of Reward: 7.283. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 428.606 s. Mean Reward: 3.791. Std of Reward: 9.909. Training.
[INFO] Exported results\rocketTest19\Rocket Capabilities\Rocket Capabilities-499988.onnx
[INFO] Exported results\rocketTest19\Rocket Capabilities\Rocket Capabilities-500052.onnx
[INFO] Copied results\rocketTest19\Rocket Capabilities\Rocket Capabilities-500052.onnx to results\rocketTest19\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________________________

increased punishment for going up from -0.005 to -0.02 + introduced the bullseye_coefficient + slight random platform spawn

2/14/25

rocketTest20

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest19\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest19\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest20\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 27.189 s. Mean Reward: -1.638. Std of Reward: 3.119. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 43.213 s. Mean Reward: -16.366. Std of Reward: 17.097. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 59.728 s. Mean Reward: -12.337. Std of Reward: 12.364. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 76.024 s. Mean Reward: -12.392. Std of Reward: 11.571. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 92.141 s. Mean Reward: -11.544. Std of Reward: 9.574. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 107.156 s. Mean Reward: -9.357. Std of Reward: 9.113. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 123.184 s. Mean Reward: -13.496. Std of Reward: 16.185. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 138.739 s. Mean Reward: -12.942. Std of Reward: 19.672. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 153.978 s. Mean Reward: -15.428. Std of Reward: 24.469. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 169.850 s. Mean Reward: -14.684. Std of Reward: 26.132. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 185.411 s. Mean Reward: -11.448. Std of Reward: 20.978. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 200.962 s. Mean Reward: -6.453. Std of Reward: 18.307. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 220.167 s. Mean Reward: -6.125. Std of Reward: 15.220. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 240.103 s. Mean Reward: -4.947. Std of Reward: 9.028. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 255.649 s. Mean Reward: -7.861. Std of Reward: 14.988. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 270.892 s. Mean Reward: -8.281. Std of Reward: 16.601. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 283.712 s. Mean Reward: -22.160. Std of Reward: 32.439. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 299.243 s. Mean Reward: -7.012. Std of Reward: 13.103. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 315.288 s. Mean Reward: -6.132. Std of Reward: 10.728. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 331.124 s. Mean Reward: -10.642. Std of Reward: 15.083. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 346.545 s. Mean Reward: -18.797. Std of Reward: 36.160. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 361.908 s. Mean Reward: -9.550. Std of Reward: 19.248. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 377.502 s. Mean Reward: -18.209. Std of Reward: 30.421. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 393.585 s. Mean Reward: -12.334. Std of Reward: 30.907. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 409.204 s. Mean Reward: -16.356. Std of Reward: 29.896. Training.
[INFO] Exported results\rocketTest20\Rocket Capabilities\Rocket Capabilities-499950.onnx
[INFO] Exported results\rocketTest20\Rocket Capabilities\Rocket Capabilities-500014.onnx
[INFO] Copied results\rocketTest20\Rocket Capabilities\Rocket Capabilities-500014.onnx to results\rocketTest20\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest21

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest20\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest20\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest21\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 22.558 s. Mean Reward: -1.004. Std of Reward: 0.026. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 37.920 s. Mean Reward: -6.082. Std of Reward: 10.466. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 53.989 s. Mean Reward: -9.657. Std of Reward: 14.671. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 69.280 s. Mean Reward: -5.530. Std of Reward: 13.008. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 85.166 s. Mean Reward: -14.893. Std of Reward: 22.586. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 101.217 s. Mean Reward: -9.412. Std of Reward: 17.225. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 117.273 s. Mean Reward: -6.119. Std of Reward: 11.401. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 133.052 s. Mean Reward: -9.245. Std of Reward: 24.355. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 148.870 s. Mean Reward: -4.315. Std of Reward: 10.170. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 165.073 s. Mean Reward: -3.460. Std of Reward: 9.133. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 180.948 s. Mean Reward: -4.829. Std of Reward: 15.861. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 197.014 s. Mean Reward: -3.689. Std of Reward: 10.412. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 213.160 s. Mean Reward: -12.218. Std of Reward: 30.539. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 228.738 s. Mean Reward: -12.101. Std of Reward: 25.151. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 244.282 s. Mean Reward: -7.997. Std of Reward: 18.049. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 260.062 s. Mean Reward: -4.748. Std of Reward: 10.367. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 275.002 s. Mean Reward: -4.646. Std of Reward: 14.308. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 290.647 s. Mean Reward: -18.983. Std of Reward: 27.576. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 302.585 s. Mean Reward: -10.200. Std of Reward: 27.059. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 318.410 s. Mean Reward: -12.066. Std of Reward: 19.398. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 333.346 s. Mean Reward: -15.705. Std of Reward: 25.636. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 349.498 s. Mean Reward: -6.953. Std of Reward: 13.082. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 365.826 s. Mean Reward: -5.552. Std of Reward: 11.681. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 382.324 s. Mean Reward: -6.319. Std of Reward: 24.597. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 397.728 s. Mean Reward: -2.671. Std of Reward: 7.272. Training.
[INFO] Exported results\rocketTest21\Rocket Capabilities\Rocket Capabilities-499962.onnx
[INFO] Exported results\rocketTest21\Rocket Capabilities\Rocket Capabilities-500026.onnx
[INFO] Copied results\rocketTest21\Rocket Capabilities\Rocket Capabilities-500026.onnx to results\rocketTest21\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest22

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest21\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest21\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest22\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 23.049 s. Mean Reward: -1.009. Std of Reward: 0.034. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 39.216 s. Mean Reward: -1.992. Std of Reward: 4.876. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 55.573 s. Mean Reward: -4.156. Std of Reward: 8.918. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 71.729 s. Mean Reward: -7.932. Std of Reward: 15.317. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 87.318 s. Mean Reward: -5.221. Std of Reward: 11.152. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 103.475 s. Mean Reward: -6.697. Std of Reward: 13.856. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 119.302 s. Mean Reward: -9.502. Std of Reward: 18.361. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 135.445 s. Mean Reward: -9.109. Std of Reward: 22.291. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 151.368 s. Mean Reward: -17.232. Std of Reward: 25.768. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 167.225 s. Mean Reward: -5.985. Std of Reward: 11.335. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 182.506 s. Mean Reward: -15.649. Std of Reward: 20.361. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 198.468 s. Mean Reward: -7.772. Std of Reward: 18.860. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 214.181 s. Mean Reward: -13.654. Std of Reward: 25.095. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 229.913 s. Mean Reward: -15.329. Std of Reward: 25.225. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 245.900 s. Mean Reward: -16.900. Std of Reward: 32.007. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 261.650 s. Mean Reward: -18.872. Std of Reward: 21.439. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 277.402 s. Mean Reward: -20.240. Std of Reward: 36.592. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 292.441 s. Mean Reward: -15.945. Std of Reward: 24.815. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 304.817 s. Mean Reward: -12.760. Std of Reward: 21.775. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 320.891 s. Mean Reward: -14.951. Std of Reward: 23.343. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 336.486 s. Mean Reward: -9.917. Std of Reward: 21.103. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 352.229 s. Mean Reward: -12.102. Std of Reward: 16.437. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 368.236 s. Mean Reward: -12.127. Std of Reward: 20.468. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 383.939 s. Mean Reward: -17.769. Std of Reward: 36.690. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 400.590 s. Mean Reward: -12.796. Std of Reward: 18.562. Training.
[INFO] Exported results\rocketTest22\Rocket Capabilities\Rocket Capabilities-499938.onnx
[INFO] Exported results\rocketTest22\Rocket Capabilities\Rocket Capabilities-500002.onnx
[INFO] Copied results\rocketTest22\Rocket Capabilities\Rocket Capabilities-500002.onnx to results\rocketTest22\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest23

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest22\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest22\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest23\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 23.068 s. Mean Reward: -1.306. Std of Reward: 2.133. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 38.680 s. Mean Reward: -4.840. Std of Reward: 10.391. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 53.662 s. Mean Reward: -14.037. Std of Reward: 17.664. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 69.695 s. Mean Reward: -16.627. Std of Reward: 21.100. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 85.181 s. Mean Reward: -9.379. Std of Reward: 15.282. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 101.296 s. Mean Reward: -19.611. Std of Reward: 29.061. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 117.836 s. Mean Reward: -21.021. Std of Reward: 28.971. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 133.838 s. Mean Reward: -12.434. Std of Reward: 21.399. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 149.962 s. Mean Reward: -14.857. Std of Reward: 22.452. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 166.214 s. Mean Reward: -19.541. Std of Reward: 24.438. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 181.051 s. Mean Reward: -30.467. Std of Reward: 22.750. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 196.525 s. Mean Reward: -12.194. Std of Reward: 20.218. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 211.793 s. Mean Reward: -15.592. Std of Reward: 28.726. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 227.636 s. Mean Reward: -27.414. Std of Reward: 18.511. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 243.259 s. Mean Reward: -19.145. Std of Reward: 34.770. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 258.758 s. Mean Reward: -9.487. Std of Reward: 20.735. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 274.867 s. Mean Reward: -18.762. Std of Reward: 27.607. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 291.016 s. Mean Reward: -11.261. Std of Reward: 25.362. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 303.717 s. Mean Reward: -16.738. Std of Reward: 25.023. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 319.377 s. Mean Reward: -19.153. Std of Reward: 26.863. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 334.578 s. Mean Reward: -21.399. Std of Reward: 28.634. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 350.252 s. Mean Reward: -18.062. Std of Reward: 31.860. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 366.162 s. Mean Reward: -12.832. Std of Reward: 18.481. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 379.399 s. Mean Reward: -27.387. Std of Reward: 35.545. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 387.904 s. Mean Reward: -6.856. Std of Reward: 15.222. Training.
[INFO] Exported results\rocketTest23\Rocket Capabilities\Rocket Capabilities-499940.onnx
[INFO] Exported results\rocketTest23\Rocket Capabilities\Rocket Capabilities-500068.onnx
[INFO] Copied results\rocketTest23\Rocket Capabilities\Rocket Capabilities-500068.onnx to results\rocketTest23\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest24
Next recording not initialzed from rocketTest24; Skipped over

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest23\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest23\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest24\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 21.110 s. Mean Reward: -0.709. Std of Reward: 2.246. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 37.393 s. Mean Reward: -6.934. Std of Reward: 10.590. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 53.662 s. Mean Reward: -8.405. Std of Reward: 11.659. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 69.355 s. Mean Reward: -14.822. Std of Reward: 16.988. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 85.010 s. Mean Reward: -14.341. Std of Reward: 20.170. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 100.328 s. Mean Reward: -17.805. Std of Reward: 23.692. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 114.975 s. Mean Reward: -14.927. Std of Reward: 16.961. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 130.174 s. Mean Reward: -20.386. Std of Reward: 21.389. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 145.722 s. Mean Reward: -19.976. Std of Reward: 28.493. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 161.156 s. Mean Reward: -21.534. Std of Reward: 24.351. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 176.709 s. Mean Reward: -22.285. Std of Reward: 23.664. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 192.570 s. Mean Reward: -16.829. Std of Reward: 20.506. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 208.653 s. Mean Reward: -19.050. Std of Reward: 32.938. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 224.330 s. Mean Reward: -18.276. Std of Reward: 30.361. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 239.798 s. Mean Reward: -18.810. Std of Reward: 41.827. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 255.643 s. Mean Reward: -31.840. Std of Reward: 35.250. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 270.568 s. Mean Reward: -22.558. Std of Reward: 31.190. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 282.511 s. Mean Reward: -12.111. Std of Reward: 20.821. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 297.864 s. Mean Reward: -23.458. Std of Reward: 30.449. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 313.272 s. Mean Reward: -15.748. Std of Reward: 21.431. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 328.148 s. Mean Reward: -20.776. Std of Reward: 35.233. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 340.093 s. Mean Reward: -14.599. Std of Reward: 26.562. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 348.469 s. Mean Reward: -20.452. Std of Reward: 29.886. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 356.800 s. Mean Reward: -25.532. Std of Reward: 30.283. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 365.143 s. Mean Reward: -24.289. Std of Reward: 39.729. Training.
[INFO] Exported results\rocketTest24\Rocket Capabilities\Rocket Capabilities-499977.onnx
[INFO] Exported results\rocketTest24\Rocket Capabilities\Rocket Capabilities-500041.onnx
[INFO] Copied results\rocketTest24\Rocket Capabilities\Rocket Capabilities-500041.onnx to results\rocketTest24\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest25; initializing from rocketTest23:

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest23\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest23\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest25\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 26.092 s. Mean Reward: -1.013. Std of Reward: 0.010. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 45.487 s. Mean Reward: -3.371. Std of Reward: 11.169. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 64.220 s. Mean Reward: -3.171. Std of Reward: 7.920. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 83.264 s. Mean Reward: -1.431. Std of Reward: 5.416. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 101.440 s. Mean Reward: -5.307. Std of Reward: 8.731. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 119.876 s. Mean Reward: -4.587. Std of Reward: 9.264. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 137.120 s. Mean Reward: -2.929. Std of Reward: 13.097. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 154.642 s. Mean Reward: -6.304. Std of Reward: 12.258. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 173.089 s. Mean Reward: -1.168. Std of Reward: 7.416. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 191.207 s. Mean Reward: -3.432. Std of Reward: 5.583. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 209.237 s. Mean Reward: -1.826. Std of Reward: 12.621. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 227.082 s. Mean Reward: -3.970. Std of Reward: 8.799. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 245.026 s. Mean Reward: -6.486. Std of Reward: 10.040. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 262.980 s. Mean Reward: -2.372. Std of Reward: 14.333. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 280.942 s. Mean Reward: -8.783. Std of Reward: 11.547. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 298.922 s. Mean Reward: -5.586. Std of Reward: 11.569. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 313.603 s. Mean Reward: -6.086. Std of Reward: 12.464. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 331.729 s. Mean Reward: -6.820. Std of Reward: 9.294. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 349.587 s. Mean Reward: -6.655. Std of Reward: 16.134. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 367.783 s. Mean Reward: -2.832. Std of Reward: 12.176. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 385.804 s. Mean Reward: -3.071. Std of Reward: 10.837. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 402.866 s. Mean Reward: -5.556. Std of Reward: 9.451. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 420.979 s. Mean Reward: -3.645. Std of Reward: 9.958. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 438.274 s. Mean Reward: -6.257. Std of Reward: 8.831. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 455.750 s. Mean Reward: -7.455. Std of Reward: 16.869. Training.
[INFO] Exported results\rocketTest25\Rocket Capabilities\Rocket Capabilities-499976.onnx
[INFO] Exported results\rocketTest25\Rocket Capabilities\Rocket Capabilities-500168.onnx
[INFO] Copied results\rocketTest25\Rocket Capabilities\Rocket Capabilities-500168.onnx to results\rocketTest25\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest26

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest25\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest25\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest26\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 29.397 s. Mean Reward: 1.122. Std of Reward: 5.696. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 47.209 s. Mean Reward: -39.103. Std of Reward: 22.092. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 64.156 s. Mean Reward: -25.692. Std of Reward: 27.132. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 81.261 s. Mean Reward: -27.202. Std of Reward: 38.019. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 98.343 s. Mean Reward: -18.256. Std of Reward: 37.314. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 116.116 s. Mean Reward: -41.450. Std of Reward: 36.906. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 134.013 s. Mean Reward: -44.468. Std of Reward: 54.682. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 151.835 s. Mean Reward: -27.700. Std of Reward: 47.239. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 169.741 s. Mean Reward: -34.988. Std of Reward: 45.816. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 187.940 s. Mean Reward: -18.479. Std of Reward: 30.110. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 206.546 s. Mean Reward: -51.367. Std of Reward: 65.743. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 225.074 s. Mean Reward: -14.482. Std of Reward: 32.561. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 242.374 s. Mean Reward: -36.766. Std of Reward: 62.194. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 259.684 s. Mean Reward: -30.561. Std of Reward: 38.393. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 277.342 s. Mean Reward: -21.100. Std of Reward: 35.883. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 294.838 s. Mean Reward: -18.526. Std of Reward: 49.497. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 309.538 s. Mean Reward: -20.143. Std of Reward: 38.207. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 327.740 s. Mean Reward: -22.706. Std of Reward: 47.175. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 345.812 s. Mean Reward: -36.757. Std of Reward: 42.233. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 364.052 s. Mean Reward: -22.392. Std of Reward: 44.641. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 382.311 s. Mean Reward: -37.096. Std of Reward: 46.506. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 399.317 s. Mean Reward: -40.230. Std of Reward: 75.038. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 417.126 s. Mean Reward: -35.742. Std of Reward: 50.919. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 437.065 s. Mean Reward: -31.297. Std of Reward: 57.510. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 447.200 s. Mean Reward: -30.574. Std of Reward: 42.743. Training.
[INFO] Exported results\rocketTest26\Rocket Capabilities\Rocket Capabilities-499967.onnx
[INFO] Exported results\rocketTest26\Rocket Capabilities\Rocket Capabilities-500031.onnx
[INFO] Copied results\rocketTest26\Rocket Capabilities\Rocket Capabilities-500031.onnx to results\rocketTest26\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest27: raised policy units to 256 from 128. Added more rockets

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[WARNING] Deleting TensorBoard data events.out.tfevents.1739595377.Halo_3.37012.0 that was left over from a previous run.
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 256
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 22.898 s. Mean Reward: -1.663. Std of Reward: 0.179. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 39.626 s. Mean Reward: -1.910. Std of Reward: 3.454. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 55.305 s. Mean Reward: -10.761. Std of Reward: 11.766. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 71.589 s. Mean Reward: -1.006. Std of Reward: 0.022. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 88.116 s. Mean Reward: -1.007. Std of Reward: 0.024. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 103.743 s. Mean Reward: -1.006. Std of Reward: 0.034. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 119.882 s. Mean Reward: -1.003. Std of Reward: 0.010. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 136.411 s. Mean Reward: -1.163. Std of Reward: 3.421. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 152.469 s. Mean Reward: -22.639. Std of Reward: 9.459. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 168.580 s. Mean Reward: -23.102. Std of Reward: 2.746. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 184.417 s. Mean Reward: -23.053. Std of Reward: 2.477. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 200.770 s. Mean Reward: -22.923. Std of Reward: 2.437. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 216.980 s. Mean Reward: -22.991. Std of Reward: 2.538. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 233.223 s. Mean Reward: -23.253. Std of Reward: 2.690. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 249.448 s. Mean Reward: -22.803. Std of Reward: 2.549. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 265.433 s. Mean Reward: -23.165. Std of Reward: 2.521. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 280.895 s. Mean Reward: -22.981. Std of Reward: 2.609. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 293.903 s. Mean Reward: -23.241. Std of Reward: 2.548. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 313.973 s. Mean Reward: -23.028. Std of Reward: 2.680. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 321.445 s. Mean Reward: -23.026. Std of Reward: 2.968. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 329.411 s. Mean Reward: -12.663. Std of Reward: 11.072. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 336.866 s. Mean Reward: -5.939. Std of Reward: 11.075. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 344.830 s. Mean Reward: -7.215. Std of Reward: 12.265. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 352.367 s. Mean Reward: -8.342. Std of Reward: 17.573. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 360.354 s. Mean Reward: -6.602. Std of Reward: 15.114. Training.
[INFO] Exported results\rocketTest27\Rocket Capabilities\Rocket Capabilities-499993.onnx
[INFO] Exported results\rocketTest27\Rocket Capabilities\Rocket Capabilities-500121.onnx
[INFO] Copied results\rocketTest27\Rocket Capabilities\Rocket Capabilities-500121.onnx to results\rocketTest27\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest28: Layer:2 Num Units: 256

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 256
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest27\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest27\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest28\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 32.147 s. Mean Reward: -2.026. Std of Reward: 10.316. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 46.367 s. Mean Reward: -9.599. Std of Reward: 16.593. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 60.499 s. Mean Reward: -6.411. Std of Reward: 10.789. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 74.277 s. Mean Reward: -30.099. Std of Reward: 25.013. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 87.828 s. Mean Reward: -24.052. Std of Reward: 27.175. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 101.307 s. Mean Reward: -33.104. Std of Reward: 13.215. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 115.736 s. Mean Reward: -23.103. Std of Reward: 2.702. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 129.886 s. Mean Reward: -19.752. Std of Reward: 7.723. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 144.403 s. Mean Reward: -3.417. Std of Reward: 6.792. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 157.881 s. Mean Reward: -15.825. Std of Reward: 15.823. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 171.903 s. Mean Reward: -11.851. Std of Reward: 14.350. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 185.663 s. Mean Reward: -26.585. Std of Reward: 20.155. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 199.054 s. Mean Reward: -33.983. Std of Reward: 25.774. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 212.457 s. Mean Reward: -37.994. Std of Reward: 21.551. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 226.137 s. Mean Reward: -28.939. Std of Reward: 18.245. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 236.995 s. Mean Reward: -27.989. Std of Reward: 20.259. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 250.616 s. Mean Reward: -29.928. Std of Reward: 17.677. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 264.773 s. Mean Reward: -22.565. Std of Reward: 20.586. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 277.947 s. Mean Reward: -22.777. Std of Reward: 20.079. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 291.952 s. Mean Reward: -18.622. Std of Reward: 21.361. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 303.291 s. Mean Reward: -13.681. Std of Reward: 20.055. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 311.803 s. Mean Reward: -19.456. Std of Reward: 20.094. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 320.148 s. Mean Reward: -19.758. Std of Reward: 24.958. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 328.446 s. Mean Reward: -16.938. Std of Reward: 20.106. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 336.627 s. Mean Reward: -20.073. Std of Reward: 25.040. Training.
[INFO] Exported results\rocketTest28\Rocket Capabilities\Rocket Capabilities-499954.onnx
[INFO] Exported results\rocketTest28\Rocket Capabilities\Rocket Capabilities-500012.onnx
[INFO] Copied results\rocketTest28\Rocket Capabilities\Rocket Capabilities-500012.onnx to results\rocketTest28\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest29: raised num layer to 3 from 2

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 256
          num_layers:   3
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 22.770 s. Mean Reward: -24.069. Std of Reward: 3.214. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 37.076 s. Mean Reward: -23.020. Std of Reward: 2.488. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 52.089 s. Mean Reward: -23.668. Std of Reward: 2.690. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 66.873 s. Mean Reward: -22.931. Std of Reward: 2.671. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 81.508 s. Mean Reward: -23.088. Std of Reward: 2.574. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 95.752 s. Mean Reward: -15.062. Std of Reward: 10.937. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 110.287 s. Mean Reward: -1.175. Std of Reward: 2.235. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 129.862 s. Mean Reward: -14.491. Std of Reward: 15.451. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 143.510 s. Mean Reward: -24.260. Std of Reward: 4.510. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 159.539 s. Mean Reward: -23.470. Std of Reward: 2.648. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 172.785 s. Mean Reward: -16.928. Std of Reward: 10.520. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 185.752 s. Mean Reward: -17.885. Std of Reward: 14.396. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 200.392 s. Mean Reward: -4.241. Std of Reward: 13.041. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 210.447 s. Mean Reward: -4.847. Std of Reward: 10.832. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 223.064 s. Mean Reward: -21.519. Std of Reward: 16.310. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 236.138 s. Mean Reward: -10.051. Std of Reward: 16.200. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 247.337 s. Mean Reward: 0.202. Std of Reward: 5.846. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 259.467 s. Mean Reward: -2.557. Std of Reward: 15.403. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 272.192 s. Mean Reward: -5.387. Std of Reward: 17.716. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 285.495 s. Mean Reward: -13.495. Std of Reward: 27.685. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 297.303 s. Mean Reward: 0.596. Std of Reward: 13.145. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 309.060 s. Mean Reward: 0.009. Std of Reward: 14.502. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 321.918 s. Mean Reward: -0.972. Std of Reward: 13.570. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 334.914 s. Mean Reward: -1.709. Std of Reward: 22.645. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 347.783 s. Mean Reward: -5.525. Std of Reward: 21.859. Training.
[INFO] Exported results\rocketTest29\Rocket Capabilities\Rocket Capabilities-499965.onnx
[INFO] Exported results\rocketTest29\Rocket Capabilities\Rocket Capabilities-500029.onnx
[INFO] Copied results\rocketTest29\Rocket Capabilities\Rocket Capabilities-500029.onnx to results\rocketTest29\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest30: initialize from 29

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 256
          num_layers:   3
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest29\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest29\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest30\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 23.699 s. Mean Reward: 1.924. Std of Reward: 6.828. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 36.813 s. Mean Reward: 1.254. Std of Reward: 9.161. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 50.154 s. Mean Reward: -1.819. Std of Reward: 14.222. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 63.449 s. Mean Reward: -2.717. Std of Reward: 15.993. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 75.965 s. Mean Reward: -7.870. Std of Reward: 27.957. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 89.105 s. Mean Reward: -1.167. Std of Reward: 15.704. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 101.650 s. Mean Reward: -7.572. Std of Reward: 27.577. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 114.763 s. Mean Reward: -6.888. Std of Reward: 26.159. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 127.969 s. Mean Reward: 0.424. Std of Reward: 11.549. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 141.573 s. Mean Reward: -13.086. Std of Reward: 30.635. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 155.288 s. Mean Reward: -3.609. Std of Reward: 19.236. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 168.280 s. Mean Reward: -24.373. Std of Reward: 49.238. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 180.907 s. Mean Reward: -3.331. Std of Reward: 18.518. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 193.372 s. Mean Reward: -1.671. Std of Reward: 20.693. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 206.174 s. Mean Reward: 1.065. Std of Reward: 12.383. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 218.823 s. Mean Reward: -3.037. Std of Reward: 20.784. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 229.202 s. Mean Reward: -3.711. Std of Reward: 26.304. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 241.751 s. Mean Reward: 0.257. Std of Reward: 16.652. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 255.504 s. Mean Reward: -3.276. Std of Reward: 16.110. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 271.562 s. Mean Reward: -5.398. Std of Reward: 19.313. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 281.078 s. Mean Reward: -1.203. Std of Reward: 13.834. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 290.464 s. Mean Reward: -5.833. Std of Reward: 23.152. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 299.118 s. Mean Reward: -2.286. Std of Reward: 15.521. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 307.780 s. Mean Reward: -9.873. Std of Reward: 23.719. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 316.826 s. Mean Reward: -10.042. Std of Reward: 27.971. Training.
[INFO] Exported results\rocketTest30\Rocket Capabilities\Rocket Capabilities-499951.onnx
[INFO] Exported results\rocketTest30\Rocket Capabilities\Rocket Capabilities-500143.onnx
[INFO] Copied results\rocketTest30\Rocket Capabilities\Rocket Capabilities-500143.onnx to results\rocketTest30\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest31; 20% model; added additional fail condition when rockets rise 50m above the lowest height they achieved in that episode

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 256
          num_layers:   3
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest30\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest30\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest31\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 32.383 s. Mean Reward: -2.248. Std of Reward: 9.502. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 53.603 s. Mean Reward: -3.568. Std of Reward: 8.978. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 68.145 s. Mean Reward: -0.608. Std of Reward: 8.108. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 83.035 s. Mean Reward: -1.208. Std of Reward: 9.773. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 96.021 s. Mean Reward: -2.017. Std of Reward: 10.465. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 110.710 s. Mean Reward: -0.253. Std of Reward: 11.937. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 125.544 s. Mean Reward: 0.292. Std of Reward: 8.958. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 138.987 s. Mean Reward: 0.931. Std of Reward: 12.451. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 152.029 s. Mean Reward: -1.888. Std of Reward: 9.217. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 165.745 s. Mean Reward: -0.187. Std of Reward: 10.899. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 180.511 s. Mean Reward: -3.849. Std of Reward: 14.435. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 194.668 s. Mean Reward: 0.647. Std of Reward: 10.673. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 208.222 s. Mean Reward: 0.652. Std of Reward: 10.446. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 220.550 s. Mean Reward: 0.641. Std of Reward: 7.041. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 234.140 s. Mean Reward: 1.002. Std of Reward: 7.892. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 246.695 s. Mean Reward: 1.511. Std of Reward: 8.566. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 257.012 s. Mean Reward: 0.301. Std of Reward: 9.237. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 270.694 s. Mean Reward: 2.807. Std of Reward: 8.965. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 280.637 s. Mean Reward: 1.136. Std of Reward: 7.508. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 289.249 s. Mean Reward: 2.763. Std of Reward: 8.252. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 297.878 s. Mean Reward: -0.059. Std of Reward: 7.706. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 306.484 s. Mean Reward: 3.172. Std of Reward: 9.556. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 315.302 s. Mean Reward: 2.775. Std of Reward: 8.705. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 323.748 s. Mean Reward: 2.464. Std of Reward: 9.580. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 332.538 s. Mean Reward: 2.856. Std of Reward: 9.002. Training.
[INFO] Exported results\rocketTest31\Rocket Capabilities\Rocket Capabilities-499940.onnx
[INFO] Exported results\rocketTest31\Rocket Capabilities\Rocket Capabilities-500004.onnx
[INFO] Copied results\rocketTest31\Rocket Capabilities\Rocket Capabilities-500004.onnx to results\rocketTest31\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest32 lowered layer count back to 2 but raise the hidden units to 512 (1st run accuracy: 4.5%)

 Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[WARNING] Deleting TensorBoard data events.out.tfevents.1740800233.Halo_3.32900.0 that was left over from a previous run.
[INFO] Hyperparameters for behavior name Rocket Capabilities:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 45.790 s. Mean Reward: -7.617. Std of Reward: 3.125. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 74.609 s. Mean Reward: -1.204. Std of Reward: 1.225. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 102.168 s. Mean Reward: -5.057. Std of Reward: 6.393. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 130.833 s. Mean Reward: -7.041. Std of Reward: 4.909. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 159.261 s. Mean Reward: -2.060. Std of Reward: 2.892. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 188.355 s. Mean Reward: -2.269. Std of Reward: 7.600. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 218.810 s. Mean Reward: -7.712. Std of Reward: 5.522. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 252.356 s. Mean Reward: -7.038. Std of Reward: 7.103. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 285.206 s. Mean Reward: -12.279. Std of Reward: 8.024. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 315.379 s. Mean Reward: -10.918. Std of Reward: 11.069. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 345.799 s. Mean Reward: -7.711. Std of Reward: 8.996. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 360.954 s. Mean Reward: -7.236. Std of Reward: 9.041. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 376.568 s. Mean Reward: -7.585. Std of Reward: 8.904. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 391.464 s. Mean Reward: -5.845. Std of Reward: 9.678. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 406.410 s. Mean Reward: -5.611. Std of Reward: 9.264. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 421.697 s. Mean Reward: -3.520. Std of Reward: 8.554. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 433.091 s. Mean Reward: -3.010. Std of Reward: 8.352. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 447.881 s. Mean Reward: -2.883. Std of Reward: 8.315. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 462.904 s. Mean Reward: -5.198. Std of Reward: 10.832. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 478.070 s. Mean Reward: -2.575. Std of Reward: 8.772. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 491.934 s. Mean Reward: -3.332. Std of Reward: 9.786. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 506.304 s. Mean Reward: -3.133. Std of Reward: 9.666. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 521.564 s. Mean Reward: -4.175. Std of Reward: 11.037. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 535.535 s. Mean Reward: -8.767. Std of Reward: 11.405. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 553.286 s. Mean Reward: -5.871. Std of Reward: 10.750. Training.
[INFO] Exported results\rocketTest32\Rocket Capabilities\Rocket Capabilities-499969.onnx
[INFO] Exported results\rocketTest32\Rocket Capabilities\Rocket Capabilities-500097.onnx
[INFO] Copied results\rocketTest32\Rocket Capabilities\Rocket Capabilities-500097.onnx to results\rocketTest32\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest32alt: raised the num layers to 3, hidden_units was 512 (1st run accuracy: 2.4%)

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   3
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 64.556 s. Mean Reward: -1.882. Std of Reward: 1.318. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 95.394 s. Mean Reward: -1.481. Std of Reward: 4.259. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 125.058 s. Mean Reward: -8.949. Std of Reward: 2.923. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 154.278 s. Mean Reward: -9.082. Std of Reward: 2.943. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 182.271 s. Mean Reward: -5.836. Std of Reward: 5.083. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 213.918 s. Mean Reward: -8.930. Std of Reward: 0.090. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 245.828 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 276.509 s. Mean Reward: -8.936. Std of Reward: 0.108. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 304.171 s. Mean Reward: -2.566. Std of Reward: 2.796. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 334.188 s. Mean Reward: -0.970. Std of Reward: 1.208. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 355.122 s. Mean Reward: -1.528. Std of Reward: 4.430. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 369.239 s. Mean Reward: -0.382. Std of Reward: 4.504. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 383.876 s. Mean Reward: -8.894. Std of Reward: 1.920. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 398.157 s. Mean Reward: -10.397. Std of Reward: 1.587. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 413.798 s. Mean Reward: -10.369. Std of Reward: 3.837. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 428.920 s. Mean Reward: -8.294. Std of Reward: 2.475. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 443.069 s. Mean Reward: -1.390. Std of Reward: 5.428. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 459.794 s. Mean Reward: -1.864. Std of Reward: 7.032. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 473.403 s. Mean Reward: -1.803. Std of Reward: 12.175. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 487.906 s. Mean Reward: -4.383. Std of Reward: 12.465. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 502.382 s. Mean Reward: -6.862. Std of Reward: 12.753. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 516.207 s. Mean Reward: -5.744. Std of Reward: 12.769. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 530.379 s. Mean Reward: -5.701. Std of Reward: 11.877. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 544.271 s. Mean Reward: -5.955. Std of Reward: 14.167. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 558.196 s. Mean Reward: -3.639. Std of Reward: 11.722. Training.
[INFO] Exported results\rocketTest32alt\Rocket Capabilities\Rocket Capabilities-499946.onnx
[INFO] Exported results\rocketTest32alt\Rocket Capabilities\Rocket Capabilities-500010.onnx
[INFO] Copied results\rocketTest32alt\Rocket Capabilities\Rocket Capabilities-500010.onnx to results\rocketTest32alt\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest32alt2 num_layers: 2 and hidden_units: 1024 (1st run accuracy: 0.75%)

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 1024
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 42.420 s. Mean Reward: -7.590. Std of Reward: 3.067. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 61.116 s. Mean Reward: -8.521. Std of Reward: 1.791. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 76.500 s. Mean Reward: -5.232. Std of Reward: 3.768. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 90.751 s. Mean Reward: -1.003. Std of Reward: 0.007. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 107.824 s. Mean Reward: -6.590. Std of Reward: 4.518. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 122.982 s. Mean Reward: -8.918. Std of Reward: 0.009. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 137.839 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 153.108 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 168.017 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 182.574 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 205.410 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 219.810 s. Mean Reward: -7.765. Std of Reward: 2.544. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 232.963 s. Mean Reward: -0.339. Std of Reward: 7.969. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 245.925 s. Mean Reward: -4.808. Std of Reward: 8.699. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 258.655 s. Mean Reward: -8.922. Std of Reward: 1.518. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 273.543 s. Mean Reward: -8.920. Std of Reward: 0.003. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 294.488 s. Mean Reward: -8.936. Std of Reward: 0.126. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 310.087 s. Mean Reward: -4.021. Std of Reward: 3.158. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 321.820 s. Mean Reward: -1.005. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 335.760 s. Mean Reward: -8.428. Std of Reward: 2.383. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 349.951 s. Mean Reward: -8.885. Std of Reward: 0.717. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 363.077 s. Mean Reward: -9.106. Std of Reward: 3.628. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 375.587 s. Mean Reward: -2.584. Std of Reward: 11.695. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 388.423 s. Mean Reward: -0.819. Std of Reward: 2.144. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 402.307 s. Mean Reward: -6.002. Std of Reward: 5.391. Training.
[INFO] Exported results\rocketTest32alt2\Rocket Capabilities\Rocket Capabilities-499988.onnx
[INFO] Exported results\rocketTest32alt2\Rocket Capabilities\Rocket Capabilities-500058.onnx
[INFO] Copied results\rocketTest32alt2\Rocket Capabilities\Rocket Capabilities-500058.onnx to results\rocketTest32alt2\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest32alt3 num_layers: 3 and hidden_units: 1024 (1st run accuracy: 2.2%)

 Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 1024
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 25.176 s. Mean Reward: -7.402. Std of Reward: 3.112. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 37.242 s. Mean Reward: -2.319. Std of Reward: 5.830. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 50.215 s. Mean Reward: -2.133. Std of Reward: 6.254. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 63.271 s. Mean Reward: -9.223. Std of Reward: 0.869. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 78.498 s. Mean Reward: -8.944. Std of Reward: 0.135. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 91.603 s. Mean Reward: -1.905. Std of Reward: 6.352. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 104.158 s. Mean Reward: -6.002. Std of Reward: 5.938. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 119.076 s. Mean Reward: -6.958. Std of Reward: 3.196. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 131.985 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 144.802 s. Mean Reward: -2.362. Std of Reward: 2.597. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 158.466 s. Mean Reward: -1.413. Std of Reward: 1.737. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 171.350 s. Mean Reward: -1.024. Std of Reward: 6.527. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 185.308 s. Mean Reward: -8.923. Std of Reward: 0.073. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 197.395 s. Mean Reward: -4.155. Std of Reward: 8.572. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 210.456 s. Mean Reward: -1.599. Std of Reward: 11.790. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 223.153 s. Mean Reward: -7.921. Std of Reward: 3.956. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 240.646 s. Mean Reward: -7.788. Std of Reward: 3.214. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 255.332 s. Mean Reward: -4.661. Std of Reward: 8.879. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 269.203 s. Mean Reward: -9.010. Std of Reward: 0.395. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 283.926 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 298.277 s. Mean Reward: -8.932. Std of Reward: 0.102. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 312.641 s. Mean Reward: -9.311. Std of Reward: 1.432. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 327.633 s. Mean Reward: -8.915. Std of Reward: 0.403. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 340.526 s. Mean Reward: -8.396. Std of Reward: 7.851. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 353.013 s. Mean Reward: -4.874. Std of Reward: 7.807. Training.
[INFO] Exported results\rocketTest32alt3\Rocket Capabilities\Rocket Capabilities-499941.onnx
[INFO] Exported results\rocketTest32alt3\Rocket Capabilities\Rocket Capabilities-500069.onnx
[INFO] Copied results\rocketTest32alt3\Rocket Capabilities\Rocket Capabilities-500069.onnx to results\rocketTest32alt3\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest33 picked best performer, num_layers 2 and hidden_units 512

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      results\rocketTest32\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest32\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest33\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 28.006 s. Mean Reward: -4.970. Std of Reward: 9.141. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 41.524 s. Mean Reward: -8.861. Std of Reward: 9.282. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 55.463 s. Mean Reward: -9.145. Std of Reward: 1.168. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 71.955 s. Mean Reward: -9.071. Std of Reward: 0.562. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 85.397 s. Mean Reward: -5.892. Std of Reward: 3.643. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 99.285 s. Mean Reward: -6.824. Std of Reward: 3.439. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 112.120 s. Mean Reward: -8.053. Std of Reward: 2.869. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 125.573 s. Mean Reward: -7.499. Std of Reward: 4.403. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 140.087 s. Mean Reward: -9.656. Std of Reward: 8.386. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 153.649 s. Mean Reward: -8.146. Std of Reward: 6.122. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 167.114 s. Mean Reward: -3.855. Std of Reward: 5.424. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 181.257 s. Mean Reward: -6.250. Std of Reward: 10.495. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 194.512 s. Mean Reward: -11.915. Std of Reward: 7.180. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 208.041 s. Mean Reward: -6.575. Std of Reward: 11.138. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 221.277 s. Mean Reward: -6.566. Std of Reward: 11.984. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 234.553 s. Mean Reward: -5.426. Std of Reward: 10.007. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 247.430 s. Mean Reward: -9.336. Std of Reward: 9.614. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 257.690 s. Mean Reward: -3.791. Std of Reward: 12.051. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 271.123 s. Mean Reward: -4.446. Std of Reward: 12.667. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 285.244 s. Mean Reward: -6.620. Std of Reward: 12.268. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 295.249 s. Mean Reward: -1.688. Std of Reward: 11.031. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 304.295 s. Mean Reward: -2.764. Std of Reward: 9.399. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 313.423 s. Mean Reward: -5.537. Std of Reward: 11.851. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 322.584 s. Mean Reward: -6.036. Std of Reward: 11.563. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 333.706 s. Mean Reward: -6.130. Std of Reward: 13.073. Training.
[INFO] Exported results\rocketTest33\Rocket Capabilities\Rocket Capabilities-499956.onnx
[INFO] Exported results\rocketTest33\Rocket Capabilities\Rocket Capabilities-500084.onnx
[INFO] Copied results\rocketTest33\Rocket Capabilities\Rocket Capabilities-500084.onnx to results\rocketTest33\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest34

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      results\rocketTest33\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest33\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest34\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 25.916 s. Mean Reward: -4.823. Std of Reward: 5.668. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 42.138 s. Mean Reward: -1.043. Std of Reward: 8.600. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 57.821 s. Mean Reward: 2.128. Std of Reward: 8.651. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 74.332 s. Mean Reward: -0.816. Std of Reward: 7.483. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 90.671 s. Mean Reward: -0.876. Std of Reward: 5.023. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 106.489 s. Mean Reward: -1.779. Std of Reward: 5.095. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 120.569 s. Mean Reward: -5.649. Std of Reward: 4.145. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 136.842 s. Mean Reward: -8.917. Std of Reward: 0.012. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 162.820 s. Mean Reward: -6.942. Std of Reward: 3.309. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 179.637 s. Mean Reward: -1.197. Std of Reward: 2.716. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 195.735 s. Mean Reward: -8.634. Std of Reward: 2.558. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 213.123 s. Mean Reward: -7.932. Std of Reward: 2.313. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 230.619 s. Mean Reward: -1.725. Std of Reward: 1.977. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 248.613 s. Mean Reward: -1.002. Std of Reward: 0.006. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 261.221 s. Mean Reward: -8.109. Std of Reward: 2.789. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 274.124 s. Mean Reward: -8.949. Std of Reward: 0.158. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 285.466 s. Mean Reward: -8.335. Std of Reward: 10.659. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 295.151 s. Mean Reward: -12.400. Std of Reward: 3.744. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 308.138 s. Mean Reward: -4.925. Std of Reward: 5.768. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 320.290 s. Mean Reward: -9.562. Std of Reward: 4.867. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 333.008 s. Mean Reward: -7.465. Std of Reward: 9.320. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 345.363 s. Mean Reward: -12.114. Std of Reward: 6.740. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 358.234 s. Mean Reward: -10.426. Std of Reward: 6.564. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 371.069 s. Mean Reward: -9.674. Std of Reward: 11.661. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 383.496 s. Mean Reward: -9.173. Std of Reward: 8.243. Training.
[INFO] Exported results\rocketTest34\Rocket Capabilities\Rocket Capabilities-499978.onnx
[INFO] Exported results\rocketTest34\Rocket Capabilities\Rocket Capabilities-500042.onnx
[INFO] Copied results\rocketTest34\Rocket Capabilities\Rocket Capabilities-500042.onnx to results\rocketTest34\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest35 3/7/25: demo recording translation2

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      results\rocketTest34\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest34\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest35\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 28.332 s. Mean Reward: -1.196. Std of Reward: 1.756. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 42.584 s. Mean Reward: -1.761. Std of Reward: 2.408. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 51.984 s. Mean Reward: -8.954. Std of Reward: 0.301. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 61.092 s. Mean Reward: -8.513. Std of Reward: 1.672. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 70.355 s. Mean Reward: -1.994. Std of Reward: 2.536. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 78.764 s. Mean Reward: -1.057. Std of Reward: 0.685. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 87.485 s. Mean Reward: -8.707. Std of Reward: 1.338. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 96.313 s. Mean Reward: -8.266. Std of Reward: 2.712. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 104.779 s. Mean Reward: -11.093. Std of Reward: 5.386. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 112.889 s. Mean Reward: -9.568. Std of Reward: 3.710. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 121.951 s. Mean Reward: -8.445. Std of Reward: 2.112. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 131.345 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 140.693 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 149.699 s. Mean Reward: -8.001. Std of Reward: 2.599. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 158.195 s. Mean Reward: -9.190. Std of Reward: 1.335. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 167.600 s. Mean Reward: -8.927. Std of Reward: 0.074. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 175.840 s. Mean Reward: -4.249. Std of Reward: 3.287. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 182.403 s. Mean Reward: -8.959. Std of Reward: 2.780. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 190.498 s. Mean Reward: -7.151. Std of Reward: 3.925. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 198.276 s. Mean Reward: -1.390. Std of Reward: 5.123. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 206.531 s. Mean Reward: -7.337. Std of Reward: 4.455. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 217.096 s. Mean Reward: -8.866. Std of Reward: 5.796. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 227.542 s. Mean Reward: -7.572. Std of Reward: 5.952. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 236.371 s. Mean Reward: -9.332. Std of Reward: 6.495. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 246.003 s. Mean Reward: -8.043. Std of Reward: 8.147. Training.
[INFO] Exported results\rocketTest35\Rocket Capabilities\Rocket Capabilities-499947.onnx
[INFO] Exported results\rocketTest35\Rocket Capabilities\Rocket Capabilities-500011.onnx
[INFO] Copied results\rocketTest35\Rocket Capabilities\Rocket Capabilities-500011.onnx to results\rocketTest35\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest36: inialize from 35, translation2

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      results\rocketTest35\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest35\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest36\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 21.751 s. Mean Reward: -4.494. Std of Reward: 4.564. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 43.361 s. Mean Reward: -8.053. Std of Reward: 2.641. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 51.636 s. Mean Reward: -8.866. Std of Reward: 2.223. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 63.654 s. Mean Reward: -8.919. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 72.417 s. Mean Reward: -5.260. Std of Reward: 3.539. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 80.988 s. Mean Reward: -8.660. Std of Reward: 2.030. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 90.012 s. Mean Reward: -8.943. Std of Reward: 0.133. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 98.031 s. Mean Reward: -2.187. Std of Reward: 5.305. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 106.347 s. Mean Reward: -8.094. Std of Reward: 8.478. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 114.716 s. Mean Reward: -4.532. Std of Reward: 6.208. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 123.236 s. Mean Reward: -1.632. Std of Reward: 3.489. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 131.631 s. Mean Reward: -1.005. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 139.975 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 148.558 s. Mean Reward: -1.045. Std of Reward: 0.571. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 160.791 s. Mean Reward: -1.758. Std of Reward: 2.202. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 173.270 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 185.460 s. Mean Reward: -3.132. Std of Reward: 3.765. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 194.187 s. Mean Reward: -8.500. Std of Reward: 2.952. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 204.294 s. Mean Reward: -8.497. Std of Reward: 4.544. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 212.859 s. Mean Reward: -3.131. Std of Reward: 4.386. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 221.318 s. Mean Reward: -2.437. Std of Reward: 3.223. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 229.783 s. Mean Reward: -4.700. Std of Reward: 4.139. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 241.032 s. Mean Reward: -4.174. Std of Reward: 5.338. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 251.820 s. Mean Reward: -6.302. Std of Reward: 6.839. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 262.526 s. Mean Reward: -7.497. Std of Reward: 8.850. Training.
[INFO] Exported results\rocketTest36\Rocket Capabilities\Rocket Capabilities-499956.onnx
[INFO] Exported results\rocketTest36\Rocket Capabilities\Rocket Capabilities-500020.onnx
[INFO] Copied results\rocketTest36\Rocket Capabilities\Rocket Capabilities-500020.onnx to results\rocketTest36\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest35alt: initalize from 34, translation1. Successes 15, rises and crashes

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest34\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest34\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest35alt\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 21.145 s. Mean Reward: -1.032. Std of Reward: 0.111. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 33.817 s. Mean Reward: -4.757. Std of Reward: 3.949. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 46.926 s. Mean Reward: -9.092. Std of Reward: 0.755. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 55.062 s. Mean Reward: -1.955. Std of Reward: 2.408. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 62.633 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 70.553 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 82.143 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 90.688 s. Mean Reward: -1.003. Std of Reward: 0.007. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 105.855 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 113.976 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 121.910 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 129.975 s. Mean Reward: -1.186. Std of Reward: 1.202. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 138.608 s. Mean Reward: -8.924. Std of Reward: 1.116. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 147.165 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 157.393 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 166.274 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 175.034 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 183.119 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 191.999 s. Mean Reward: -9.061. Std of Reward: 0.630. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 199.902 s. Mean Reward: -3.081. Std of Reward: 3.739. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 207.497 s. Mean Reward: -7.357. Std of Reward: 3.944. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 215.155 s. Mean Reward: -3.627. Std of Reward: 6.949. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 223.438 s. Mean Reward: -4.898. Std of Reward: 5.990. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 230.972 s. Mean Reward: -11.733. Std of Reward: 2.675. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 239.880 s. Mean Reward: -12.375. Std of Reward: 2.220. Training.
[INFO] Exported results\rocketTest35alt\Rocket Capabilities\Rocket Capabilities-499978.onnx
[INFO] Exported results\rocketTest35alt\Rocket Capabilities\Rocket Capabilities-500106.onnx
[INFO] Copied results\rocketTest35alt\Rocket Capabilities\Rocket Capabilities-500106.onnx to results\rocketTest35alt\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest36alt: initialize from 35alt

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation1.demo
        init_path:      results\rocketTest35alt\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest35alt\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest36alt\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 20.100 s. Mean Reward: -8.918. Std of Reward: 0.018. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 33.020 s. Mean Reward: -9.163. Std of Reward: 1.451. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 42.201 s. Mean Reward: -8.919. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 50.734 s. Mean Reward: -5.210. Std of Reward: 3.707. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 58.761 s. Mean Reward: -1.006. Std of Reward: 0.015. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 66.859 s. Mean Reward: -1.008. Std of Reward: 0.010. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 74.601 s. Mean Reward: -1.009. Std of Reward: 0.020. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 82.569 s. Mean Reward: -1.007. Std of Reward: 0.013. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 90.651 s. Mean Reward: -1.008. Std of Reward: 0.019. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 98.362 s. Mean Reward: -1.004. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 106.322 s. Mean Reward: -1.003. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 114.654 s. Mean Reward: -1.003. Std of Reward: 0.008. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 122.421 s. Mean Reward: -3.118. Std of Reward: 3.677. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 131.035 s. Mean Reward: -8.921. Std of Reward: 0.067. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 139.793 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 149.802 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 158.727 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 166.830 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 176.896 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 185.688 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 194.116 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 204.464 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 216.835 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 231.556 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 244.601 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Exported results\rocketTest36alt\Rocket Capabilities\Rocket Capabilities-499965.onnx
[INFO] Exported results\rocketTest36alt\Rocket Capabilities\Rocket Capabilities-500001.onnx
[INFO] Copied results\rocketTest36alt\Rocket Capabilities\Rocket Capabilities-500001.onnx to results\rocketTest36alt\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest37: initialize from rocketTest36, translation2

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      results\rocketTest36\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest36\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest37\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 23.754 s. Mean Reward: -0.658. Std of Reward: 3.726. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 32.174 s. Mean Reward: -7.999. Std of Reward: 5.797. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 40.292 s. Mean Reward: -10.117. Std of Reward: 3.357. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 48.821 s. Mean Reward: -6.845. Std of Reward: 6.206. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 57.589 s. Mean Reward: -7.439. Std of Reward: 4.333. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 65.847 s. Mean Reward: -4.529. Std of Reward: 4.904. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 74.722 s. Mean Reward: -1.014. Std of Reward: 0.063. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 82.363 s. Mean Reward: -8.705. Std of Reward: 1.795. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 91.437 s. Mean Reward: -8.945. Std of Reward: 0.153. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 99.739 s. Mean Reward: -4.478. Std of Reward: 4.299. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 107.954 s. Mean Reward: -8.894. Std of Reward: 3.234. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 116.681 s. Mean Reward: -8.918. Std of Reward: 0.010. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 125.828 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 134.570 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 144.241 s. Mean Reward: -8.933. Std of Reward: 0.085. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 153.583 s. Mean Reward: -3.657. Std of Reward: 4.044. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 162.111 s. Mean Reward: -9.514. Std of Reward: 6.502. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 168.580 s. Mean Reward: -8.078. Std of Reward: 5.081. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 176.792 s. Mean Reward: -4.477. Std of Reward: 5.334. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 184.919 s. Mean Reward: -2.959. Std of Reward: 4.084. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 192.918 s. Mean Reward: -7.286. Std of Reward: 5.332. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 201.154 s. Mean Reward: -8.007. Std of Reward: 5.423. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 209.058 s. Mean Reward: -6.679. Std of Reward: 5.365. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 217.198 s. Mean Reward: -6.135. Std of Reward: 6.102. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 227.900 s. Mean Reward: -9.377. Std of Reward: 5.831. Training.
[INFO] Exported results\rocketTest37\Rocket Capabilities\Rocket Capabilities-499983.onnx
[INFO] Exported results\rocketTest37\Rocket Capabilities\Rocket Capabilities-500047.onnx
[INFO] Copied results\rocketTest37\Rocket Capabilities\Rocket Capabilities-500047.onnx to results\rocketTest37\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest38

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      results\rocketTest37\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest37\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest38\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 22.530 s. Mean Reward: -1.413. Std of Reward: 3.159. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 34.936 s. Mean Reward: -0.838. Std of Reward: 3.204. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 47.401 s. Mean Reward: -1.003. Std of Reward: 0.007. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 59.878 s. Mean Reward: -7.351. Std of Reward: 5.326. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 74.514 s. Mean Reward: -8.918. Std of Reward: 0.010. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 87.564 s. Mean Reward: -7.109. Std of Reward: 3.915. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 96.416 s. Mean Reward: -8.637. Std of Reward: 1.563. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 105.903 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 115.017 s. Mean Reward: -8.933. Std of Reward: 0.099. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 123.001 s. Mean Reward: -5.196. Std of Reward: 5.618. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 131.316 s. Mean Reward: -3.885. Std of Reward: 5.007. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 141.007 s. Mean Reward: -1.134. Std of Reward: 4.846. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 148.879 s. Mean Reward: -3.280. Std of Reward: 5.641. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 157.324 s. Mean Reward: -4.286. Std of Reward: 5.934. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 166.152 s. Mean Reward: -9.178. Std of Reward: 2.387. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 174.083 s. Mean Reward: -1.988. Std of Reward: 3.595. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 182.271 s. Mean Reward: -7.949. Std of Reward: 4.157. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 189.654 s. Mean Reward: -8.943. Std of Reward: 0.231. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 197.835 s. Mean Reward: -6.921. Std of Reward: 3.400. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 207.521 s. Mean Reward: -5.974. Std of Reward: 6.346. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 216.584 s. Mean Reward: -7.362. Std of Reward: 5.082. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 225.796 s. Mean Reward: -3.975. Std of Reward: 5.736. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 241.587 s. Mean Reward: -4.027. Std of Reward: 5.152. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 250.740 s. Mean Reward: -5.922. Std of Reward: 6.587. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 262.467 s. Mean Reward: -5.420. Std of Reward: 5.713. Training.
[INFO] Exported results\rocketTest38\Rocket Capabilities\Rocket Capabilities-499999.onnx
[INFO] Exported results\rocketTest38\Rocket Capabilities\Rocket Capabilities-500044.onnx
[INFO] Copied results\rocketTest38\Rocket Capabilities\Rocket Capabilities-500044.onnx to results\rocketTest38\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest39: unusually poor performance

Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 512
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/translation2.demo
        init_path:      results\rocketTest38\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/translation2.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest38\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest39\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 18.146 s. Mean Reward: -1.126. Std of Reward: 0.894. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 31.417 s. Mean Reward: -3.943. Std of Reward: 4.076. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 41.953 s. Mean Reward: -8.974. Std of Reward: 0.388. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 50.882 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 59.623 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 68.341 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 82.356 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 95.779 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 105.091 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 114.694 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 123.553 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 132.307 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 141.044 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 149.896 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 159.096 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 167.893 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 178.340 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 187.116 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 194.422 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 203.478 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 213.686 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 224.635 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 235.867 s. Mean Reward: -8.920. Std of Reward: 0.000. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 245.340 s. Mean Reward: -8.927. Std of Reward: 0.114. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 257.225 s. Mean Reward: -8.150. Std of Reward: 2.438. Training.
[INFO] Exported results\rocketTest39\Rocket Capabilities\Rocket Capabilities-499963.onnx
[INFO] Exported results\rocketTest39\Rocket Capabilities\Rocket Capabilities-500155.onnx
[INFO] Copied results\rocketTest39\Rocket Capabilities\Rocket Capabilities-500155.onnx to results\rocketTest39\Rocket Capabilities.onnx.

______________________________________________________________________________________________________________________

rocketTest40

