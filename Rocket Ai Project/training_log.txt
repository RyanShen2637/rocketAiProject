1/10/25

rocketTest1
 
Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording1.demo
        init_path:      None
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Resuming from results\rocketTest1\Rocket Capabilities.
[INFO] Resuming training from step 250928.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 28.647 s. Mean Reward: -0.778. Std of Reward: 0.629. Training.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 74.886 s. Mean Reward: -0.846. Std of Reward: 0.533. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 121.945 s. Mean Reward: -0.912. Std of Reward: 0.410. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 169.739 s. Mean Reward: -0.833. Std of Reward: 0.553. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 214.942 s. Mean Reward: -0.806. Std of Reward: 0.591. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 255.674 s. Mean Reward: -0.783. Std of Reward: 0.622. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 297.120 s. Mean Reward: -0.803. Std of Reward: 0.596. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 340.955 s. Mean Reward: -0.606. Std of Reward: 0.795. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 379.683 s. Mean Reward: -0.800. Std of Reward: 0.600. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 399.261 s. Mean Reward: -0.725. Std of Reward: 0.689. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 417.969 s. Mean Reward: -0.660. Std of Reward: 0.752. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 435.845 s. Mean Reward: -0.308. Std of Reward: 0.951. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 455.504 s. Mean Reward: -0.450. Std of Reward: 0.893. Training.
[INFO] Exported results\rocketTest1\Rocket Capabilities\Rocket Capabilities-499969.onnx
[INFO] Exported results\rocketTest1\Rocket Capabilities\Rocket Capabilities-500033.onnx
[INFO] Copied results\rocketTest1\Rocket Capabilities\Rocket Capabilities-500033.onnx to results\rocketTest1\Rocket Capabilities.onnx.

----------------------------------------------------------------------------------------------------------------------

rocketTest2

 Version information:
  ml-agents: 1.1.0,
  ml-agents-envs: 1.1.0,
  Communicator API: 1.5.0,
  PyTorch: 2.2.2+cu121
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0
[INFO] Connected new brain: Rocket Capabilities?team=0
[INFO] Hyperparameters for behavior name Rocket Capabilities:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  10240
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
          gail:
            gamma:      0.99
            strength:   0.5
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
            learning_rate:      0.0003
            encoding_size:      None
            use_actions:        False
            use_vail:   False
            demo_path:  rocketRecordings/recording1.demo
        init_path:      results\rocketTest1\Rocket Capabilities\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      500000
        time_horizon:   64
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:
          demo_path:    rocketRecordings/recording1.demo
          steps:        0
          strength:     0.5
          samples_per_update:   0
          num_epoch:    None
          batch_size:   None
[INFO] Initializing from results\rocketTest1\Rocket Capabilities\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\rocketTest2\Rocket Capabilities.
C:\Users\ryanr\OneDrive\Documents\GitHub\rocketAiProject\Rocket Ai Project\venv\lib\site-packages\torch\utils\_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3641.)
  return func(*args, **kwargs)
[INFO] Rocket Capabilities. Step: 20000. Time Elapsed: 57.018 s. Mean Reward: -0.791. Std of Reward: 0.612. Training.
[INFO] Rocket Capabilities. Step: 40000. Time Elapsed: 74.481 s. Mean Reward: -0.778. Std of Reward: 0.629. Training.
[INFO] Rocket Capabilities. Step: 60000. Time Elapsed: 92.117 s. Mean Reward: -0.798. Std of Reward: 0.603. Training.
[INFO] Rocket Capabilities. Step: 80000. Time Elapsed: 120.330 s. Mean Reward: -0.811. Std of Reward: 0.586. Training.
[INFO] Rocket Capabilities. Step: 100000. Time Elapsed: 170.490 s. Mean Reward: -0.917. Std of Reward: 0.400. Training.
[INFO] Rocket Capabilities. Step: 120000. Time Elapsed: 188.099 s. Mean Reward: -0.783. Std of Reward: 0.623. Training.
[INFO] Rocket Capabilities. Step: 140000. Time Elapsed: 205.444 s. Mean Reward: -0.710. Std of Reward: 0.705. Training.
[INFO] Rocket Capabilities. Step: 160000. Time Elapsed: 226.988 s. Mean Reward: -0.719. Std of Reward: 0.695. Training.
[INFO] Rocket Capabilities. Step: 180000. Time Elapsed: 244.491 s. Mean Reward: -0.611. Std of Reward: 0.792. Training.
[INFO] Rocket Capabilities. Step: 200000. Time Elapsed: 261.881 s. Mean Reward: -0.489. Std of Reward: 0.872. Training.
[INFO] Rocket Capabilities. Step: 220000. Time Elapsed: 279.689 s. Mean Reward: -0.753. Std of Reward: 0.658. Training.
[INFO] Rocket Capabilities. Step: 240000. Time Elapsed: 302.969 s. Mean Reward: -0.714. Std of Reward: 0.700. Training.
[INFO] Rocket Capabilities. Step: 260000. Time Elapsed: 336.854 s. Mean Reward: -0.783. Std of Reward: 0.622. Training.
[INFO] Rocket Capabilities. Step: 280000. Time Elapsed: 383.137 s. Mean Reward: -0.483. Std of Reward: 0.876. Training.
[INFO] Rocket Capabilities. Step: 300000. Time Elapsed: 410.943 s. Mean Reward: -0.500. Std of Reward: 0.866. Training.
[INFO] Rocket Capabilities. Step: 320000. Time Elapsed: 454.589 s. Mean Reward: -0.737. Std of Reward: 0.676. Training.
[INFO] Rocket Capabilities. Step: 340000. Time Elapsed: 475.341 s. Mean Reward: -0.676. Std of Reward: 0.736. Training.
[INFO] Rocket Capabilities. Step: 360000. Time Elapsed: 492.524 s. Mean Reward: -0.636. Std of Reward: 0.771. Training.
[INFO] Rocket Capabilities. Step: 380000. Time Elapsed: 509.912 s. Mean Reward: -0.581. Std of Reward: 0.814. Training.
[INFO] Rocket Capabilities. Step: 400000. Time Elapsed: 527.746 s. Mean Reward: -0.750. Std of Reward: 0.661. Training.
[INFO] Rocket Capabilities. Step: 420000. Time Elapsed: 544.975 s. Mean Reward: -0.526. Std of Reward: 0.850. Training.
[INFO] Rocket Capabilities. Step: 440000. Time Elapsed: 562.815 s. Mean Reward: -0.435. Std of Reward: 0.901. Training.
[INFO] Rocket Capabilities. Step: 460000. Time Elapsed: 580.351 s. Mean Reward: -0.111. Std of Reward: 0.994. Training.
[INFO] Rocket Capabilities. Step: 480000. Time Elapsed: 597.538 s. Mean Reward: -0.238. Std of Reward: 0.971. Training.
[INFO] Rocket Capabilities. Step: 500000. Time Elapsed: 614.879 s. Mean Reward: -0.304. Std of Reward: 0.953. Training.
[INFO] Exported results\rocketTest2\Rocket Capabilities\Rocket Capabilities-499989.onnx
[INFO] Exported results\rocketTest2\Rocket Capabilities\Rocket Capabilities-500053.onnx
[INFO] Copied results\rocketTest2\Rocket Capabilities\Rocket Capabilities-500053.onnx to results\rocketTest2\Rocket Capabilities.onnx.

-------------------------------------------------------------------------------------------------------------------------